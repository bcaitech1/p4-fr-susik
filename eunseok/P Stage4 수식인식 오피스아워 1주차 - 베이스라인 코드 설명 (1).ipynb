{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7796d316",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"https://i.imgur.com/oGGIYjQ.jpg\" width=100%>\n",
    "<br>\n",
    "\n",
    "# 수식인식 1주차 오피스아워 \n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "<br>\n",
    "<div align='right'><b>멘토 성민석(Minsuk Sung)</b></div>\n",
    "<div align='right'>고려대학교 인공지능학과</div>\n",
    "<div align='right'>minsuksung@korea.ac.kr</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1699a3f",
   "metadata": {},
   "source": [
    "> 주의: 본 컨텐츠는 **[저작권법 제25조 제2항](https://glaw.scourt.go.kr/wsjo/lawod/sjo192.do?contId=2135829&jomunNo=25)**에 의해 강의 목적으로 이용한 저작물이 포함되어 있으므로  \n",
    "> 해당 자료를 <font color='red'><b>외부에 공개 및 게시하는 것을 금지</b></font>하며 이를 위반하는 경우 저작권 침해로서 관련법에 따라 처벌될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350041c3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "toc": true
   },
   "source": [
    "<h1>목차<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#전체-개요-설명\" data-toc-modified-id=\"전체-개요-설명-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>전체 개요 설명</a></span></li><li><span><a href=\"#베이스라인-구조\" data-toc-modified-id=\"베이스라인-구조-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>베이스라인 구조</a></span></li><li><span><a href=\"#가상-환경-확인-및-설정\" data-toc-modified-id=\"가상-환경-확인-및-설정-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>가상 환경 확인 및 설정</a></span></li></ul></li><li><span><a href=\"#Overvall-architecture\" data-toc-modified-id=\"Overvall-architecture-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Overvall architecture</a></span></li><li><span><a href=\"#checkpoint.py\" data-toc-modified-id=\"checkpoint.py-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>checkpoint.py</a></span><ul class=\"toc-item\"><li><span><a href=\"#save_checkpoint\" data-toc-modified-id=\"save_checkpoint-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>save_checkpoint</a></span></li><li><span><a href=\"#load_checkpoint\" data-toc-modified-id=\"load_checkpoint-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>load_checkpoint</a></span></li><li><span><a href=\"#init_tensorboard\" data-toc-modified-id=\"init_tensorboard-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>init_tensorboard</a></span></li><li><span><a href=\"#write_tensorboard\" data-toc-modified-id=\"write_tensorboard-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>write_tensorboard</a></span></li></ul></li><li><span><a href=\"#dataset.py\" data-toc-modified-id=\"dataset.py-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>dataset.py</a></span><ul class=\"toc-item\"><li><span><a href=\"#load_vocab\" data-toc-modified-id=\"load_vocab-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>load_vocab</a></span><ul class=\"toc-item\"><li><span><a href=\"#간단한-예시\" data-toc-modified-id=\"간단한-예시-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>간단한 예시</a></span></li></ul></li><li><span><a href=\"#encode_truth\" data-toc-modified-id=\"encode_truth-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>encode_truth</a></span><ul class=\"toc-item\"><li><span><a href=\"#간단한-예시\" data-toc-modified-id=\"간단한-예시-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>간단한 예시</a></span></li></ul></li><li><span><a href=\"#split_gt\" data-toc-modified-id=\"split_gt-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>split_gt</a></span></li><li><span><a href=\"#collate_batch\" data-toc-modified-id=\"collate_batch-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>collate_batch</a></span><ul class=\"toc-item\"><li><span><a href=\"#간단한-예시\" data-toc-modified-id=\"간단한-예시-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>간단한 예시</a></span></li></ul></li><li><span><a href=\"#LoadDataset\" data-toc-modified-id=\"LoadDataset-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>LoadDataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#간단한-예시\" data-toc-modified-id=\"간단한-예시-4.5.1\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>간단한 예시</a></span></li></ul></li><li><span><a href=\"#dataset_loader\" data-toc-modified-id=\"dataset_loader-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>dataset_loader</a></span></li></ul></li><li><span><a href=\"#networks\" data-toc-modified-id=\"networks-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>networks</a></span><ul class=\"toc-item\"><li><span><a href=\"#CNN\" data-toc-modified-id=\"CNN-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>CNN</a></span></li><li><span><a href=\"#AttentionCell\" data-toc-modified-id=\"AttentionCell-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>AttentionCell</a></span></li><li><span><a href=\"#AttentionDecoder\" data-toc-modified-id=\"AttentionDecoder-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>AttentionDecoder</a></span><ul class=\"toc-item\"><li><span><a href=\"#teacher-forcing-technique\" data-toc-modified-id=\"teacher-forcing-technique-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>teacher forcing technique</a></span></li></ul></li><li><span><a href=\"#Attention\" data-toc-modified-id=\"Attention-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Attention</a></span></li><li><span><a href=\"#모델-구조-변경-관련-TIP\" data-toc-modified-id=\"모델-구조-변경-관련-TIP-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>모델 구조 변경 관련 TIP</a></span></li></ul></li><li><span><a href=\"#BREAK-TIME\" data-toc-modified-id=\"BREAK-TIME-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>BREAK TIME</a></span></li><li><span><a href=\"#configs\" data-toc-modified-id=\"configs-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>configs</a></span><ul class=\"toc-item\"><li><span><a href=\"#YAML-Ain't-Markup-Language\" data-toc-modified-id=\"YAML-Ain't-Markup-Language-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>YAML Ain't Markup Language</a></span></li><li><span><a href=\"#Attention.yaml\" data-toc-modified-id=\"Attention.yaml-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Attention.yaml</a></span></li></ul></li><li><span><a href=\"#flags.py\" data-toc-modified-id=\"flags.py-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>flags.py</a></span></li><li><span><a href=\"#utils\" data-toc-modified-id=\"utils-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>utils</a></span><ul class=\"toc-item\"><li><span><a href=\"#get_network\" data-toc-modified-id=\"get_network-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>get_network</a></span></li><li><span><a href=\"#get_optimizer\" data-toc-modified-id=\"get_optimizer-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>get_optimizer</a></span></li></ul></li><li><span><a href=\"#metrics.py\" data-toc-modified-id=\"metrics.py-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>metrics.py</a></span><ul class=\"toc-item\"><li><span><a href=\"#평가방법\" data-toc-modified-id=\"평가방법-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>평가방법</a></span></li><li><span><a href=\"#sentence_acc\" data-toc-modified-id=\"sentence_acc-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>sentence_acc</a></span></li><li><span><a href=\"#word_error_rate\" data-toc-modified-id=\"word_error_rate-10.3\"><span class=\"toc-item-num\">10.3&nbsp;&nbsp;</span>word_error_rate</a></span><ul class=\"toc-item\"><li><span><a href=\"#간단한-예시\" data-toc-modified-id=\"간단한-예시-10.3.1\"><span class=\"toc-item-num\">10.3.1&nbsp;&nbsp;</span>간단한 예시</a></span></li></ul></li></ul></li><li><span><a href=\"#train.py\" data-toc-modified-id=\"train.py-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>train.py</a></span><ul class=\"toc-item\"><li><span><a href=\"#id_to_string\" data-toc-modified-id=\"id_to_string-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>id_to_string</a></span></li><li><span><a href=\"#run_epoch\" data-toc-modified-id=\"run_epoch-11.2\"><span class=\"toc-item-num\">11.2&nbsp;&nbsp;</span>run_epoch</a></span></li><li><span><a href=\"#main\" data-toc-modified-id=\"main-11.3\"><span class=\"toc-item-num\">11.3&nbsp;&nbsp;</span>main</a></span><ul class=\"toc-item\"><li><span><a href=\"#학습-시작!\" data-toc-modified-id=\"학습-시작!-11.3.1\"><span class=\"toc-item-num\">11.3.1&nbsp;&nbsp;</span>학습 시작!</a></span></li></ul></li></ul></li><li><span><a href=\"#inference.py\" data-toc-modified-id=\"inference.py-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>inference.py</a></span><ul class=\"toc-item\"><li><span><a href=\"#제출-포맷\" data-toc-modified-id=\"제출-포맷-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>제출 포맷</a></span></li><li><span><a href=\"#Submission-확인하기\" data-toc-modified-id=\"Submission-확인하기-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;</span>Submission 확인하기</a></span></li><li><span><a href=\"#추론-결과-확인하기\" data-toc-modified-id=\"추론-결과-확인하기-12.3\"><span class=\"toc-item-num\">12.3&nbsp;&nbsp;</span>추론 결과 확인하기</a></span></li></ul></li><li><span><a href=\"#QnA\" data-toc-modified-id=\"QnA-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>QnA</a></span></li><li><span><a href=\"#Further-reading\" data-toc-modified-id=\"Further-reading-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Further reading</a></span></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663b7287",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "\n",
    "> 잠깐! 해당 내용은 중고급자가 아닌 **초급자를 위한 내용**임을 숙지해주시길 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f683717",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 전체 개요 설명\n",
    "\n",
    "<img src=\"https://images.unsplash.com/photo-1581089778245-3ce67677f718?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1050&q=80\" width=40% align='center'>\n",
    "<a href='https://images.unsplash.com/photo-1581089778245-3ce67677f718?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1050&q=80'><div align='center'>출처: Unsplash</div></a>\n",
    "\n",
    "**`수식인식(Math expression recognition)`** 은 수식이 있는 이미지를 입력으로 받아 LaTex 형태로 변환하는 문제입니다. 수식인식은 이미지를 입력으로 받아 텍스트를 출력한다는 관점에서 `광학 문자 인식(Optical Character Recognition, OCR)`의 한 종류라고 볼 수 있습니다. 이번 대회에서는 광학 문자 인식 모델들과 수식인식 데이터를 이용하여, 수식 인식 모델을 학습하고, 그 성능을 높이는 작업을 할 예정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d653a29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "$$ \\frac{dT}{dt} = \\frac{dQ}{dt} \\rightarrow \\text{ \\frac { d T } { d t } = \\frac { d Q } { d t } }$$\n",
    "\n",
    "<br>\n",
    "\n",
    "위의 예시를 보면 분수 표현을 \\frac{ }{ } 이라는 LaTeX로 표현한다는 것으로 보아 `Multi line recognition이 필요하다`는 것을 쉽게 확인할 수 있습니다. 또한, dt와 dT에도 순서가 맞아야 제대로 인식되기 때문에 어느정도 `순서도 인식해야한다`는 점도 확인할 수 있습니다. 이렇듯 수식인식 문제는 단순하게 수식을 인식하는 문제로도 볼 수 있지만 기존 single line recognition 기반의 OCR이 아닌 `multi line recognition을 이용하는 OCR task로도 인식`할 수 있습니다. Multi line recognition 이란 관점에서 기존 OCR과는 차별화되는 task라고 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f115db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 베이스라인 구조\n",
    "\n",
    "기본적으로 제공해드리는 코드의 구조는 아래와 같이 설계되어 있습니다. 이번 강의에서는 캠퍼분들이 대회를 진행하실 때 필수적으로 알아야하는 코드들 위주로 정리해드리겠습니다. 본 오피스아워에서 다룰 코드는 <font color='red'>checkpoint.py / flags.py / utils.py / dataset.py / train.py / metrics.py / inference.py</font> 를 다룹니다.\n",
    "\n",
    "```bash\n",
    "baseline code  \n",
    "├── README.md  \n",
    "├── requirements.txt  \n",
    "└── src  \n",
    "    ├── checkpoint.py → 모델의 체크포인트 관련\n",
    "    ├── configs  \n",
    "    │   ├── Attention.yaml → 모델 학습의 hyperparams 관련\n",
    "    │   └── SATRN.yaml  \n",
    "    ├── dataset.py → 대회에서 사용할 수식인식 데이터셋과 관련\n",
    "    ├── data_tools  \n",
    "    │   ├── extract_tokens.py  \n",
    "    │   ├── parse_upstage.py  \n",
    "    │   └── train_test_split.py  \n",
    "    ├── flags.py  \n",
    "    ├── inference.py → 제출을 위한 submission 파일 생성 관련\n",
    "    ├── log  \n",
    "    │   └── satrn  \n",
    "    ├── metrics.py → 대회의 평가방법 관련 (WER, Sentence ACC)\n",
    "    ├── networks\n",
    "    │   ├── Attention.py → 모델 관련\n",
    "    │   ├── SATRN.py  \n",
    "    │   └── spatial_transformation.py\n",
    "    ├── scheduler.py\n",
    "    ├── submission.txt\n",
    "    ├── train.py → 모델 학습 관련\n",
    "    └── utils.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5515369",
   "metadata": {},
   "source": [
    "### 가상 환경 확인 및 설정\n",
    "베이스라인을 돌리기 위해서는 `requirements.txt`에 있는 라이브러리와 일치시켜두도록 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c4ef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:09:30.113866Z",
     "start_time": "2021-05-28T09:09:30.096562Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45adc46f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:09:34.009437Z",
     "start_time": "2021-05-28T09:09:33.628831Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f88e120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:09:35.862550Z",
     "start_time": "2021-05-28T09:09:35.854835Z"
    }
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189252ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:09:59.577440Z",
     "start_time": "2021-05-28T09:09:59.451034Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963a213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:10:08.244763Z",
     "start_time": "2021-05-28T09:10:08.118058Z"
    }
   },
   "outputs": [],
   "source": [
    "!cat ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddafa229",
   "metadata": {},
   "source": [
    "> <font color='red'>HINT</font> : 만약 아직 라이브러리 설치를 안하셨다면 아래 명령어로 설치하세요!\n",
    ">```bash\n",
    "$ pip install -r ../requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dfb3a0",
   "metadata": {},
   "source": [
    "> <font color='red'>HINT</font> : 만약 아직 데이터를 다운받지 못하셨다면 아래 명령어로 다운받으세요!\n",
    ">```bash\n",
    "$ wget https://prod-aistages-public.s3.amazonaws.com/app/Competitions/000043/data/train_dataset.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8428b11c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:10:54.108028Z",
     "start_time": "2021-05-28T09:10:52.640151Z"
    }
   },
   "outputs": [],
   "source": [
    "!conda list | grep -E 'torch|torchvision|editdistance|numpy|scipy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ca8e4",
   "metadata": {},
   "source": [
    "## Overvall architecture\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "수식인식 대회의 베이스라인 구조를 한눈에 살펴봅시다. 여러 번의 대회를 진행해보셔서 잘 아시겠지만, 역시 모델 학습하는 코드를 중심으로 대부분의 코드가 동작합니다. 그러한 이유로 이번 오피스아워에서도 학습에 필요한 모듈을 중심으로 설명드릴 예정입니다. 시간 관계상 이 중에서도 학습에 필수적이라고 판단되는 모듈들만 소개드리겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbe5061",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/7RKH5yw.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea94111",
   "metadata": {},
   "source": [
    "아래와 같은 순서로 강의는 진행될 예정입니다. \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<div align='center'><font size=5>checkpoint.py → dataset.py → networks → config.py → utils.py → metrics.py → train.py</font></div>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ae570d",
   "metadata": {},
   "source": [
    "## checkpoint.py\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "체크포인트를 정의하는 파일입니다. 여기에서 학습 과정 중 모델의 학습 Loss와 대회 평가 지표인 WER이나 Sentence Acc와 같은 정보를 저장하고 불러옵니다. 추가적으로 이러한 정보를 TensorBoard에서 확인할 수 있도록 합니다. 최초 학습 시에는 default_checkpoint 를 통해서 초기화를 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d59d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T13:17:34.822964Z",
     "start_time": "2021-05-25T13:17:34.146834Z"
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "import os\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "default_checkpoint = {\n",
    "    \"epoch\": 0,\n",
    "    \n",
    "    # train\n",
    "    \"train_losses\": [],\n",
    "    \"train_symbol_accuracy\": [],\n",
    "    \"train_sentence_accuracy\": [],\n",
    "    \"train_wer\": [],\n",
    "    \n",
    "    # valid\n",
    "    \"validation_losses\": [],\n",
    "    \"validation_symbol_accuracy\": [],\n",
    "    \"validation_sentence_accuracy\": [],\n",
    "    \"validation_wer\": [],\n",
    "    \n",
    "    \"lr\": [], \n",
    "    \"grad_norm\": [], # clip_grad_norm\n",
    "    \"model\": {},\n",
    "    \"configs\":{},\n",
    "    \"token_to_id\":{},\n",
    "    \"id_to_token\":{},\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0df7952",
   "metadata": {},
   "source": [
    "### save_checkpoint\n",
    "체크포인트를 저장합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f18659",
   "metadata": {},
   "source": [
    "```python\n",
    "def save_checkpoint(checkpoint, dir=\"./checkpoints\", prefix=\"\"):\n",
    "    # Padded to 4 digits because of lexical sorting of numbers.\n",
    "    # e.g. 0009.pth\n",
    "    filename = \"{num:0>4}.pth\".format(num=checkpoint[\"epoch\"])\n",
    "    if not os.path.exists(os.path.join(prefix, dir)):\n",
    "        os.makedirs(os.path.join(prefix, dir))\n",
    "    torch.save(checkpoint, os.path.join(prefix, dir, filename))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6603ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:12:56.099192Z",
     "start_time": "2021-05-28T09:12:56.090852Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted(os.listdir('./log/attention_50/checkpoints'))[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d68e29b",
   "metadata": {},
   "source": [
    "### load_checkpoint\n",
    "체크포인트를 불러옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e4b4c6",
   "metadata": {},
   "source": [
    "```python\n",
    "def load_checkpoint(path, cuda=use_cuda):\n",
    "    if cuda:\n",
    "        return torch.load(path)\n",
    "    else:\n",
    "        # Load GPU model on CPU\n",
    "        return torch.load(path, map_location=lambda storage, loc: storage)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d9218",
   "metadata": {},
   "source": [
    "### init_tensorboard\n",
    "\n",
    "> <font color='red'>HINT</font> : 개인 로컬에서 TensorBoard를 사용하고 싶으시다면, 아래와 같이 입력해주세요!\n",
    ">```bash\n",
    "$ tensorboard --logdir=./log/ --host=YOUR_ADDR --port=6006\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1819087a",
   "metadata": {},
   "source": [
    "```python\n",
    "def init_tensorboard(name=\"\", base_dir=\"./tensorboard\"):\n",
    "    return SummaryWriter(os.path.join(name, base_dir))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4f83f8",
   "metadata": {},
   "source": [
    "### write_tensorboard\n",
    "```python\n",
    "def write_tensorboard(\n",
    "    writer,\n",
    "    epoch,\n",
    "    grad_norm,\n",
    "    train_loss,\n",
    "    train_symbol_accuracy,\n",
    "    train_sentence_accuracy,\n",
    "    train_wer,\n",
    "    validation_loss,\n",
    "    validation_symbol_accuracy,\n",
    "    validation_sentence_accuracy,\n",
    "    validation_wer,\n",
    "    model,\n",
    "):\n",
    "    writer.add_scalar(\"train_loss\", train_loss, epoch)\n",
    "    writer.add_scalar(\"train_symbol_accuracy\", train_symbol_accuracy, epoch)\n",
    "    writer.add_scalar(\"train_sentence_accuracy\",train_sentence_accuracy,epoch)\n",
    "    writer.add_scalar(\"train_wer\", train_wer, epoch)\n",
    "    writer.add_scalar(\"validation_loss\", validation_loss, epoch)\n",
    "    writer.add_scalar(\"validation_symbol_accuracy\", validation_symbol_accuracy, epoch)\n",
    "    writer.add_scalar(\"validation_sentence_accuracy\",validation_sentence_accuracy,epoch)\n",
    "    writer.add_scalar(\"validation_wer\",validation_wer,epoch)\n",
    "    writer.add_scalar(\"grad_norm\", grad_norm, epoch)\n",
    "\n",
    "    for name, param in model.encoder.named_parameters():\n",
    "        writer.add_histogram(\n",
    "            \"encoder/{}\".format(name), param.detach().cpu().numpy(), epoch\n",
    "        )\n",
    "        if param.grad is not None:\n",
    "            writer.add_histogram(\n",
    "                \"encoder/{}/grad\".format(name), param.grad.detach().cpu().numpy(), epoch\n",
    "            )\n",
    "\n",
    "    for name, param in model.decoder.named_parameters():\n",
    "        writer.add_histogram(\n",
    "            \"decoder/{}\".format(name), param.detach().cpu().numpy(), epoch\n",
    "        )\n",
    "        if param.grad is not None:\n",
    "            writer.add_histogram(\n",
    "                \"decoder/{}/grad\".format(name), param.grad.detach().cpu().numpy(), epoch\n",
    "            )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75748e32",
   "metadata": {},
   "source": [
    "## dataset.py\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "데이터셋을 학습 및 검증 테이터를 읽어오는 파일입니다. 여기에는 수식의 처음을 가리키는 SOS 토큰과 과 끝을 가리키는 EOS 토큰들과 학습에 사용될 토큰들을 불러옵니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc696fbf",
   "metadata": {},
   "source": [
    "```python\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image, ImageOps\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "START = \"<SOS>\"\n",
    "END = \"<EOS>\"\n",
    "PAD = \"<PAD>\"\n",
    "SPECIAL_TOKENS = [START, END, PAD]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc231d3",
   "metadata": {},
   "source": [
    "### load_vocab\n",
    "학습에 필요한 vocab을 가져오는 함수입니다. `tokens_paths`를 통해서 토큰이 저장되어 있는 위치를 확인하세요. 해당 함수를 통해서 토큰의 값을 id로, id를 값으로 가지고 올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb2714",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:16:18.984466Z",
     "start_time": "2021-05-28T09:16:18.976972Z"
    }
   },
   "outputs": [],
   "source": [
    "os.listdir('../../train_dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a92712e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T13:17:59.161585Z",
     "start_time": "2021-05-25T13:17:59.155568Z"
    },
    "code_folding": []
   },
   "source": [
    "```python\n",
    "def load_vocab(tokens_paths):\n",
    "    tokens = []\n",
    "    tokens.extend(SPECIAL_TOKENS)\n",
    "    for tokens_file in tokens_paths:\n",
    "        with open(tokens_file, \"r\") as fd:\n",
    "            reader = fd.read()\n",
    "            for token in reader.split(\"\\n\"):\n",
    "                if token not in tokens:\n",
    "                    tokens.append(token)\n",
    "    token_to_id = {tok: i for i, tok in enumerate(tokens)}\n",
    "    id_to_token = {i: tok for i, tok in enumerate(tokens)}\n",
    "    return token_to_id, id_to_token\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5785d871",
   "metadata": {},
   "source": [
    "#### 간단한 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2654014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:17:11.766844Z",
     "start_time": "2021-05-28T09:17:11.179112Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import load_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a4391f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:17:32.583371Z",
     "start_time": "2021-05-28T09:17:32.577048Z"
    }
   },
   "outputs": [],
   "source": [
    "token_to_id, id_to_token = load_vocab(['../../train_dataset/tokens.txt']) # YAML 파일이므로 예제는 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b15de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:17:34.787179Z",
     "start_time": "2021-05-28T09:17:34.781561Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"현재 총 {len(id_to_token)}개의 토큰이 존재합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca58ad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:17:47.212301Z",
     "start_time": "2021-05-28T09:17:47.194001Z"
    }
   },
   "outputs": [],
   "source": [
    "token_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e3efda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:18:29.529863Z",
     "start_time": "2021-05-28T09:18:29.523206Z"
    }
   },
   "outputs": [],
   "source": [
    "token_to_id['\\\\sin'] # \\는 escape문장이므로 2번!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400056a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:18:47.384395Z",
     "start_time": "2021-05-28T09:18:47.366092Z"
    }
   },
   "outputs": [],
   "source": [
    "id_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e7ef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:18:54.584961Z",
     "start_time": "2021-05-28T09:18:54.578366Z"
    }
   },
   "outputs": [],
   "source": [
    "id_to_token[158]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d90b6e5",
   "metadata": {},
   "source": [
    "### encode_truth\n",
    "ground truth 값을 id별로 encoding해주는 함수입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f89dfd",
   "metadata": {},
   "source": [
    "```python\n",
    "def encode_truth(truth, token_to_id):\n",
    "    truth_tokens = truth.split()\n",
    "    for token in truth_tokens:\n",
    "        if token not in token_to_id:\n",
    "            # Rather ignorant way to encode the truth, but at least it works.\n",
    "            raise Exception(\"Truth contains unknown token\")\n",
    "    truth_tokens = [token_to_id[x] for x in truth_tokens]\n",
    "    if '' in truth_tokens: truth_tokens.remove('')\n",
    "    return truth_tokens\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6f9dc6",
   "metadata": {},
   "source": [
    "#### 간단한 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3a171",
   "metadata": {},
   "source": [
    "$$ a ^ 2 + b ^ 2 = c ^ 2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ab249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:20:08.960385Z",
     "start_time": "2021-05-28T09:20:08.956230Z"
    }
   },
   "outputs": [],
   "source": [
    "truth =  'a ^ 2 + b ^ 2 = c ^ 2' # 입력시 토큰 단위별로 띄어쓰기 주의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d609f7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:20:30.448294Z",
     "start_time": "2021-05-28T09:20:30.443986Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import encode_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7008e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:20:33.350601Z",
     "start_time": "2021-05-28T09:20:33.343369Z"
    }
   },
   "outputs": [],
   "source": [
    "# token -> id\n",
    "encode_truth(truth, token_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7767592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:21:01.975986Z",
     "start_time": "2021-05-28T09:21:01.967560Z"
    }
   },
   "outputs": [],
   "source": [
    "# id -> token\n",
    "list(map(lambda x: id_to_token[x], encode_truth(truth, token_to_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a01eb64",
   "metadata": {},
   "source": [
    "Jupyter Notebook 에서 matploblib을 이용해서 LaTeX을 렌더링해보고 싶다면 아래와 같은 옵션을 켜주시면 됩니다.\n",
    "\n",
    "```python\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "\n",
    "def render_latex(latex, dpi=30, return_type=None):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes() \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.axis('off')\n",
    "    plt.text(0.5,0.5,'$$%s$$' %latex, size=40, horizontalalignment='center', verticalalignment='center')\n",
    "    if not return_type:\n",
    "        plt.show()\n",
    "        return \n",
    "    else:\n",
    "        fig.canvas.draw()\n",
    "        plt.close()\n",
    "        return np.array(fig.canvas.renderer._renderer)\n",
    "             \n",
    "render_latex(truth)\n",
    "```\n",
    "\n",
    "> <font color='red'>HINT</font> : 만약 위의 옵션 실행시 뜬다면 아래 명령어를 입력해주세요\n",
    ">```bash\n",
    "$ sudo apt-get install texlive-latex-extra texlive-fonts-recommended dvipng cm-super\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e47cfb8",
   "metadata": {},
   "source": [
    "### split_gt\n",
    "모두 익히 잘 아는 train/test split 함수입니다. 해당 함수를 통해서 적절한 비율만큼 test을 구성할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e5a3d",
   "metadata": {},
   "source": [
    "```python\n",
    "def split_gt(groundtruth, proportion=1.0, test_percent=None):\n",
    "    root = os.path.join(os.path.dirname(groundtruth), \"images\")\n",
    "    with open(groundtruth, \"r\") as fd:\n",
    "        data=[]\n",
    "        for line in fd:\n",
    "            data.append(line.strip().split(\"\\t\"))\n",
    "        random.shuffle(data)\n",
    "        dataset_len = round(len(data) * proportion)\n",
    "        data = data[:dataset_len]\n",
    "        data = [[os.path.join(root, x[0]), x[1]] for x in data]\n",
    "    \n",
    "    if test_percent:\n",
    "        test_len = round(len(data) * test_percent)\n",
    "        return data[test_len:], data[:test_len]\n",
    "    else:\n",
    "        return data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875387de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:23:29.309067Z",
     "start_time": "2021-05-28T09:23:29.304830Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import split_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602a3ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:23:49.738558Z",
     "start_time": "2021-05-28T09:23:49.261517Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "train_data, valid_data = [], [] \n",
    "\n",
    "for i, path in tqdm_notebook(enumerate([\"../../train_dataset/gt.txt\"])):\n",
    "    prop = 1.0\n",
    "    train, valid = split_gt(path, prop, 0.2)\n",
    "    train_data += train\n",
    "    valid_data += valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d07af2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:23:51.558468Z",
     "start_time": "2021-05-28T09:23:51.552204Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bd594c",
   "metadata": {},
   "source": [
    "### collate_batch\n",
    "\n",
    "batch 단위별로 나오던 데이터의 순서를 바꿔주는 함수입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db3db29",
   "metadata": {},
   "source": [
    "```python\n",
    "def collate_batch(data):\n",
    "    max_len = max([len(d[\"truth\"][\"encoded\"]) for d in data])\n",
    "    # Padding with -1, will later be replaced with the PAD token\n",
    "    padded_encoded = [\n",
    "        d[\"truth\"][\"encoded\"] + (max_len - len(d[\"truth\"][\"encoded\"])) * [-1]\n",
    "        for d in data\n",
    "    ]\n",
    "    return {\n",
    "        \"path\": [d[\"path\"] for d in data],\n",
    "        # \"file_path\":[d[\"file_path\"] for d in data], # for eval batch\n",
    "        \"image\": torch.stack([d[\"image\"] for d in data], dim=0),\n",
    "        \"truth\": {\n",
    "            \"text\": [d[\"truth\"][\"text\"] for d in data],\n",
    "            \"encoded\": torch.tensor(padded_encoded)\n",
    "        },\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af33c43a",
   "metadata": {},
   "source": [
    "> <font color='red'>HINT</font> : collate는 '함께 합치다'라는 의미입니다\n",
    "\n",
    "직관적인 예시로는 프린터기에서 인쇄할때, `묶어서 인쇄하기`와 같은 기능이라고 생각하면 됩니다.  \n",
    "즉, ((피처1, 라벨1) (피처2, 라벨2))와 같은 배치 단위 데이터가 ((피처1, 피처2), (라벨1, 라벨2))와 같이 바뀝니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24452756",
   "metadata": {},
   "source": [
    "<img src=\"https://www.coastalcreative.com/wp-content/uploads/2019/10/collated-not-collated-543x600.jpg\" width=50%>\n",
    "<a href='https://www.coastalcreative.com/wp-content/uploads/2019/10/collated-not-collated-543x600.jpg'><div align='center'>출처: https://coastalcreative.com</div></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8624304d",
   "metadata": {},
   "source": [
    "#### 간단한 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d831476a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:26:16.444663Z",
     "start_time": "2021-05-28T09:26:16.439977Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e5331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:26:27.185329Z",
     "start_time": "2021-05-28T09:26:27.175083Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        x = np.random.rand(1000, 3)  # 1000 3-dim samples\n",
    "        self.x = [x[i].tolist() for i in range(1000)]\n",
    "        y = np.random.randint(low=0, high=2, size=(1000,))\n",
    "        self.y = [y[i] for i in range(1000)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c62b6e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:26:42.847796Z",
     "start_time": "2021-05-28T09:26:42.843434Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    print('Original:', batch)\n",
    "    data_list, label_list = [], []\n",
    "    for _data, _label in batch:\n",
    "        data_list.append(_data)\n",
    "        label_list.append(_label)\n",
    "    return torch.Tensor(data_list), torch.LongTensor(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd0a183",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:26:44.404948Z",
     "start_time": "2021-05-28T09:26:44.397432Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = MyDataset()\n",
    "# print(dataset[0])  # 3개의 피처, 1개 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e224d531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:26:45.146938Z",
     "start_time": "2021-05-28T09:26:45.132480Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=3,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=collate_fn  # 순서를 바꾸고 싶을때\n",
    "                        )\n",
    "\n",
    "for data, label in dataloader:\n",
    "    print(data)\n",
    "    print(label)\n",
    "    break  # 첫번째 batch에 대해서만 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45ebbb",
   "metadata": {},
   "source": [
    "> <font color='red'>HINT</font> : 그럼 이렇게 귀찮은 작업을 왜 해야할까요? 예컨대 Conv2D를 사용하는 대부분의 PyTorch 모델들은 데이터 피딩을 받는 shape이 우리가 흔히 아는 `(batch_size, height, width, channel)`과 같은 순서이지만 Transformer와 같은 경우는 이와 달라질 경우가 있을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7d54d4",
   "metadata": {},
   "source": [
    "### LoadDataset\n",
    "\n",
    "dataset은 `__init__`, `__len__`, 그리고 `__getitem__`함수만 구현해둔 상태입니다. 기본적인 preprocessing과 transformation만 설정해두었습니다. 앞선 스테이지에서 활용하셨던 [albumentations](https://github.com/albumentations-team/albumentations)과 같은 라이브러리를 활용하시는 것도 좋은 방법 중 하나입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673f33f",
   "metadata": {},
   "source": [
    "> <font color='red'>HINT</font> : 강의(5강)에서도 나왔지만 `LoadDataset`과 `DataLoader`를 혼동하지 마세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e4a52",
   "metadata": {},
   "source": [
    "```python\n",
    "class LoadDataset(Dataset):\n",
    "    \"\"\"Load Dataset\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        groundtruth,\n",
    "        tokens_file,\n",
    "        crop=False,\n",
    "        transform=None,\n",
    "        rgb=3,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            groundtruth (string): Path to ground truth TXT/TSV file\n",
    "            tokens_file (string): Path to tokens TXT file\n",
    "            ext (string): Extension of the input files\n",
    "            crop (bool, optional): Crop images to their bounding boxes [Default: False]\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        super(LoadDataset, self).__init__()\n",
    "        self.crop = crop\n",
    "        self.transform = transform\n",
    "        self.rgb = rgb\n",
    "        self.token_to_id, self.id_to_token = load_vocab(tokens_file)\n",
    "        self.data = [\n",
    "            {\n",
    "                \"path\": p,\n",
    "                \"truth\": {\n",
    "                    \"text\": truth,\n",
    "                    \"encoded\": [\n",
    "                        self.token_to_id[START],\n",
    "                        *encode_truth(truth, self.token_to_id),\n",
    "                        self.token_to_id[END],\n",
    "                    ],\n",
    "                },\n",
    "            }\n",
    "            for p, truth in groundtruth\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        item = self.data[i]\n",
    "        image = Image.open(item[\"path\"])\n",
    "        if self.rgb == 3:\n",
    "            image = image.convert(\"RGB\")\n",
    "        elif self.rgb == 1:\n",
    "            image = image.convert(\"L\")\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if self.crop:\n",
    "            bounding_box = ImageOps.invert(image).getbbox()\n",
    "            image = image.crop(bounding_box)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return {\n",
    "            \"path\": item[\"path\"], # 피처\n",
    "            \"truth\": item[\"truth\"], \n",
    "            \"image\": image # 라벨\n",
    "        }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5caf30",
   "metadata": {},
   "source": [
    "#### 간단한 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff81b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:32:58.765238Z",
     "start_time": "2021-05-28T09:32:58.688256Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3f53e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:33:07.506046Z",
     "start_time": "2021-05-28T09:33:07.500444Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "transformed = transforms.Compose(\n",
    "    [\n",
    "        # Resize so all images have the same size\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7226f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:33:08.409309Z",
     "start_time": "2021-05-28T09:33:08.406244Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import LoadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3add5ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:33:09.851169Z",
     "start_time": "2021-05-28T09:33:09.233137Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = LoadDataset(\n",
    "    train_data, \n",
    "    ['../../train_dataset/tokens.txt'],\n",
    "    crop=True, \n",
    "    transform=transformed, \n",
    "    rgb=1 # 1은 흑백, 3은 RGB\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5cd1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:33:32.363306Z",
     "start_time": "2021-05-28T09:33:32.344266Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33bc56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:34:59.404428Z",
     "start_time": "2021-05-28T09:34:59.285270Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_dataset[0]['image'].numpy()[0], cmap='gray')\n",
    "plt.title('{}\\n{}'.format(train_dataset[0]['truth']['text'], \n",
    "                          train_dataset[0]['truth']['encoded']))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d625cd18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:35:26.639163Z",
     "start_time": "2021-05-28T09:35:26.634722Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import DataLoader, collate_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f0be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:35:41.901226Z",
     "start_time": "2021-05-28T09:35:41.896243Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd72cfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:35:44.636582Z",
     "start_time": "2021-05-28T09:35:43.982299Z"
    }
   },
   "outputs": [],
   "source": [
    "d = next(iter(train_data_loader))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3137f353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:37:31.863909Z",
     "start_time": "2021-05-28T09:37:31.856629Z"
    }
   },
   "outputs": [],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a324d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:37:37.724399Z",
     "start_time": "2021-05-28T09:37:37.717354Z"
    }
   },
   "outputs": [],
   "source": [
    "d['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f63df89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:37:42.165660Z",
     "start_time": "2021-05-28T09:37:42.152333Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d['image'] # X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c1854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:37:46.262300Z",
     "start_time": "2021-05-28T09:37:46.251283Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d['truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33b5dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:37:49.352788Z",
     "start_time": "2021-05-28T09:37:49.345311Z"
    }
   },
   "outputs": [],
   "source": [
    "d['truth']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8887652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T09:37:54.466064Z",
     "start_time": "2021-05-28T09:37:54.453756Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d['truth']['encoded'] # 사실상 target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9071e00",
   "metadata": {},
   "source": [
    "### dataset_loader\n",
    "\n",
    "지금까지 만든 dataset과 dataloader를 하나의 함수로 만들어서 사용할 수 있게 만들어둡니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed7d0a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T13:48:45.937759Z",
     "start_time": "2021-05-25T13:48:45.922528Z"
    },
    "code_folding": []
   },
   "source": [
    "```python\n",
    "def dataset_loader(options, transformed):\n",
    "\n",
    "    # Read data\n",
    "    train_data, valid_data = [], [] \n",
    "    if options.data.random_split:\n",
    "        for i, path in enumerate(options.data.train):\n",
    "            prop = 1.0\n",
    "            if len(options.data.dataset_proportions) > i:\n",
    "                prop = options.data.dataset_proportions[i]\n",
    "            train, valid = split_gt(path, prop, options.data.test_proportions)\n",
    "            train_data += train\n",
    "            valid_data += valid\n",
    "    else:\n",
    "        for i, path in enumerate(options.data.train):\n",
    "            prop = 1.0\n",
    "            if len(options.data.dataset_proportions) > i:\n",
    "                prop = options.data.dataset_proportions[i]\n",
    "            train_data += split_gt(path, prop)\n",
    "        for i, path in enumerate(options.data.test):\n",
    "            valid = split_gt(path)\n",
    "            valid_data += valid\n",
    "\n",
    "    # Load data\n",
    "    train_dataset = LoadDataset(\n",
    "        train_data, \n",
    "        options.data.token_paths, \n",
    "        crop=options.data.crop, \n",
    "        transform=transformed, \n",
    "        rgb=options.data.rgb\n",
    "    )\n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=options.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=options.num_workers,\n",
    "        collate_fn=collate_batch,\n",
    "    )\n",
    "\n",
    "    valid_dataset = LoadDataset(\n",
    "        valid_data, \n",
    "        options.data.token_paths,\n",
    "        crop=options.data.crop, \n",
    "        transform=transformed, \n",
    "        rgb=options.data.rgb\n",
    "    )\n",
    "    valid_data_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=options.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=options.num_workers,\n",
    "        collate_fn=collate_batch,\n",
    "    )\n",
    "\n",
    "    return train_data_loader, valid_data_loader, train_dataset, valid_dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66161995",
   "metadata": {},
   "source": [
    "## networks\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "\n",
    "학습에 사용되는 network의 파일들이 저장되있는 디렉토리입니다. 이번 오피스아워에서는 **attention 기반의 모델**만 간단하게 설명드리고 넘어갈 예정입니다. 이미 1주차 강의에서 강사님께서 꼼꼼하게 코드를 설명해주셨기 때문에 시간 관계상 모델 설명하는 부분은 넘어가도록 하겠습니다. 베이스라인에 있던 SATRN 모델은 2주차 강의에 포함되어 있습니다. 이점 참고해주시길 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6d585",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<div align='center'><font size=5>모델과 관련된 자세한 내용은 강의 5강과 6강을 참고해주세요 :)</font></div>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src=\"https://i.imgur.com/T9OJN4q.jpg\"></td>\n",
    "<td><img src=\"https://i.imgur.com/4S5NSpV.jpg\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "<br>\n",
    "<br>\n",
    "<div align='center'>출처: 수식인식 5강 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01a40c",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "from dataset import START, PAD\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3a1f5",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a7d60",
   "metadata": {},
   "source": [
    "```python\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, nc, leakyRelu=False):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        ks = [3, 3, 3, 3, 3, 3, 2]  # kernel size\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0]  # padding\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1]  # stride\n",
    "        nm = [64, 128, 256, 256, 512, 512, 512]  # channel 수\n",
    "\n",
    "        def convRelu(i, batchNormalization=False):\n",
    "            cnn = nn.Sequential()\n",
    "            nIn = nc if i == 0 else nm[i - 1]\n",
    "            nOut = nm[i]\n",
    "            cnn.add_module('conv{0}'.format(i),\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            if batchNormalization:\n",
    "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
    "            if leakyRelu:\n",
    "                cnn.add_module('relu{0}'.format(i),\n",
    "                               nn.LeakyReLU(0.2, inplace=True))\n",
    "            else:\n",
    "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
    "            return cnn\n",
    "\n",
    "        self.conv0 = convRelu(0)\n",
    "        self.pooling0 = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = convRelu(1)\n",
    "        self.pooling1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = convRelu(2, True)\n",
    "        self.conv3 = convRelu(3)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 2), (2, 1), (0, 1))\n",
    "        self.conv4 = convRelu(4, True)\n",
    "        self.conv5 = convRelu(5)\n",
    "        self.pooling5 = nn.MaxPool2d((2, 2), (2, 1), (0, 1))\n",
    "        self.conv6 = convRelu(6, True)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = self.conv0(input)     # [batch size, 64, 128, 128]\n",
    "        out = self.pooling0(out)    # [batch size, 64, 64, 64]\n",
    "        out = self.conv1(out)       # [batch size, 128, 64, 64]\n",
    "        out = self.pooling1(out)    # [batch size, 128, 32, 32]\n",
    "        out = self.conv2(out)       # [batch size, 256, 32, 32]\n",
    "        out = self.conv3(out)       # [batch size, 256, 32, 32]\n",
    "        out = self.pooling3(out)    # [batch size, 256, 16, 33]\n",
    "        out = self.conv4(out)       # [batch size, 512, 16, 33]\n",
    "        out = self.conv5(out)       # [batch size, 512, 16, 33]\n",
    "        out = self.pooling5(out)    # [batch size, 512, 8, 34]\n",
    "        out = self.conv6(out)       # [batch size, 512, 7, 33]\n",
    "        return out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd2288",
   "metadata": {},
   "source": [
    "### AttentionCell\n",
    "\n",
    "<img src=\"https://i.imgur.com/3twCVRu.jpg\" width=60%>\n",
    "<div align='center'>출처: 수식인식 6강</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8793448c",
   "metadata": {},
   "source": [
    "```python\n",
    "class AttentionCell(nn.Module):\n",
    "    def __init__(self, src_dim, hidden_dim, embedding_dim, num_layers=1, cell_type='LSTM'):\n",
    "        super(AttentionCell, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.i2h = nn.Linear(src_dim, hidden_dim, bias=False)  # src는 CNN에서 온 값\n",
    "        self.h2h = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.score = nn.Linear(hidden_dim, 1, bias=False)\n",
    "        if num_layers == 1:\n",
    "            if cell_type == 'LSTM':\n",
    "                self.rnn = nn.LSTMCell(src_dim + embedding_dim, hidden_dim)\n",
    "            elif cell_type == 'GRU':\n",
    "                self.rnn = nn.GRUCell(src_dim + embedding_dim, hidden_dim)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        else:\n",
    "            if cell_type == 'LSTM':\n",
    "                self.rnn = nn.ModuleList(\n",
    "                    [nn.LSTMCell(src_dim + embedding_dim, hidden_dim)]\n",
    "                    + [\n",
    "                        nn.LSTMCell(hidden_dim, hidden_dim)\n",
    "                        for _ in range(num_layers - 1)\n",
    "                    ]\n",
    "                )\n",
    "            elif cell_type == 'GRU':\n",
    "                self.rnn = nn.ModuleList(\n",
    "                    [nn.GRUCell(src_dim + embedding_dim, hidden_dim)]\n",
    "                    + [\n",
    "                        nn.GRUCell(hidden_dim, hidden_dim)\n",
    "                        for _ in range(num_layers - 1)\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, prev_hidden, src, tgt):   # src: [b, L, c]\n",
    "        src_features = self.i2h(src)  # [b, L, h]\n",
    "        if self.num_layers == 1:\n",
    "            # 0: hidden state / 1: cell state\n",
    "            prev_hidden_proj = self.h2h(prev_hidden[0]).unsqueeze(1)    # [b, 1, h]\n",
    "        else:\n",
    "            prev_hidden_proj = self.h2h(prev_hidden[-1][0]).unsqueeze(1)    # [b, 1, h]\n",
    "        attention_logit = self.score(\n",
    "            torch.tanh(src_features + prev_hidden_proj) # [b, L, h]\n",
    "        )  # [b, L, 1]\n",
    "        alpha = F.softmax(attention_logit, dim=1)  # [b, L, 1]\n",
    "        context = torch.bmm(alpha.permute(0, 2, 1), src).squeeze(1)  # [b, c]\n",
    "\n",
    "        concat_context = torch.cat([context, tgt], 1)  # [b, c+e]\n",
    "\n",
    "        if self.num_layers == 1:\n",
    "            cur_hidden = self.rnn(concat_context, prev_hidden)\n",
    "        else:\n",
    "            cur_hidden = []\n",
    "            for i, layer in enumerate(self.rnn):\n",
    "                if i == 0:\n",
    "                    concat_context = layer(concat_context, prev_hidden[i])\n",
    "                else:\n",
    "                    concat_context = layer(concat_context[0], prev_hidden[i])\n",
    "                cur_hidden.append(concat_context)\n",
    "\n",
    "        return cur_hidden, alpha\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3b4b38",
   "metadata": {},
   "source": [
    "### AttentionDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41caadb",
   "metadata": {},
   "source": [
    "```python\n",
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes,\n",
    "        src_dim,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        pad_id,\n",
    "        st_id,\n",
    "        num_layers=1,\n",
    "        cell_type='LSTM',\n",
    "        checkpoint=None,\n",
    "    ):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(num_classes + 1, embedding_dim)  # start token 추가\n",
    "        self.attention_cell = AttentionCell( # Attention 계산을 위한 Cell\n",
    "            src_dim, hidden_dim, embedding_dim, num_layers, cell_type\n",
    "        )\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.generator = nn.Linear(hidden_dim, num_classes)\n",
    "        self.pad_id = pad_id\n",
    "        self.st_id = st_id\n",
    "\n",
    "        if checkpoint is not None:\n",
    "            self.load_state_dict(checkpoint)\n",
    "\n",
    "    def forward(\n",
    "        self, src, text, is_train=True, teacher_forcing_ratio=1.0, batch_max_length=50\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input:\n",
    "            batch_H : contextual_feature H = hidden state of encoder.\n",
    "            [batch_size x num_steps x contextual_feature_channels]\n",
    "            text : the text-index of each image. \n",
    "            [batch_size x (max_length+1)]. +1 for [START] token. text[:, 0] = [START].\n",
    "        output:\n",
    "            probability distribution at each step [batch_size x num_steps x num_classes]\n",
    "        \"\"\"\n",
    "        batch_size = src.size(0)\n",
    "        num_steps = batch_max_length - 1  # +1 for [s] at end of sentence.\n",
    "\n",
    "        output_hiddens = (\n",
    "            torch.FloatTensor(batch_size, num_steps, self.hidden_dim).fill_(0).to(device) # LSTM 통과한 결과를 한꺼번에 계산\n",
    "        )\n",
    "        \n",
    "        if self.num_layers == 1:\n",
    "            hidden = (\n",
    "                # 2개를 만드는 이유: LSTM는 hidden state / cell state 필요\n",
    "                # GRU를 사용하게 될 경우 나중에 달라질 수 있음\n",
    "                torch.FloatTensor(batch_size, self.hidden_dim).fill_(0).to(device), # hidden state\n",
    "                torch.FloatTensor(batch_size, self.hidden_dim).fill_(0).to(device), # cell state\n",
    "            )\n",
    "        else:\n",
    "            hidden = [\n",
    "                (\n",
    "                    torch.FloatTensor(batch_size, self.hidden_dim).fill_(0).to(device),\n",
    "                    torch.FloatTensor(batch_size, self.hidden_dim).fill_(0).to(device),\n",
    "                )\n",
    "                for _ in range(self.num_layers)\n",
    "            ]\n",
    "\n",
    "        if is_train and random.random() < teacher_forcing_ratio:\n",
    "            for i in range(num_steps):\n",
    "                # one-hot vectors for a i-th char. in a batch\n",
    "                embedd = self.embedding(text[:, i])  # text가 정답!\n",
    "                # hidden : decoder's hidden s_{t-1}, \n",
    "                # batch_H : encoder's hidden H,\n",
    "                # char_onehots : one-hot(y_{t-1})\n",
    "                hidden, alpha = self.attention_cell(hidden, src, embedd)  # 여기서 alpha값이 attn score\n",
    "                if self.num_layers == 1:\n",
    "                    output_hiddens[:, i, :] = hidden[\n",
    "                        0\n",
    "                    ]  # LSTM hidden index (0: hidden, 1: Cell)\n",
    "                else:\n",
    "                    output_hiddens[:, i, :] = hidden[-1][0]\n",
    "            probs = self.generator(output_hiddens)\n",
    "\n",
    "        else:\n",
    "            targets = (\n",
    "                torch.LongTensor(batch_size).fill_(self.st_id).to(device)\n",
    "            )  # [START] token\n",
    "            probs = (\n",
    "                torch.FloatTensor(batch_size,\n",
    "                                  num_steps, \n",
    "                                  self.num_classes).fill_(0).to(device)\n",
    "            )  # 최종적으로 나와야할 값 - 전체 시퀀스에서 각각에 대한 확률\n",
    "\n",
    "            for i in range(num_steps):\n",
    "                embedd = self.embedding(targets)\n",
    "                hidden, alpha = self.attention_cell(hidden, src, embedd)\n",
    "                if self.num_layers == 1:\n",
    "                    probs_step = self.generator(hidden[0])  # teacher forcing이 아니기 때문에 바로 결과\n",
    "                else:\n",
    "                    probs_step = self.generator(hidden[-1][0])\n",
    "                probs[:, i, :] = probs_step\n",
    "                _, next_input = probs_step.max(1)\n",
    "                targets = next_input\n",
    "\n",
    "        return probs  # batch_size x num_steps x num_classes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3123ee7b",
   "metadata": {},
   "source": [
    "#### teacher forcing technique\n",
    "Teacher forcing 기법은 <font color='red'><b>Ground Truth를 디코더의 다음 입력으로 넣어주는 기법</b></font>입니다.  \n",
    "(Teacher forcing is the technique where the target word is passed as the next input to the decoder.)\n",
    "\n",
    "<img src=\"https://i.imgur.com/gXcCxdw.jpg\">\n",
    "<div align='center'><a herf=\"https://towardsdatascience.com/what-is-teacher-forcing-3da6217fed1c\">출처: towardsdatascience</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced97cf3",
   "metadata": {},
   "source": [
    "정말 직관적인 예시는 아래와 같습니다.\n",
    "\n",
    "> 문제 A: 어떠한 값(`a`)을 구하시오.  \n",
    "> 문제 B: 문제 A의 답(`a`)을 이용하여 `b`를 구하시오.  \n",
    "> 문제 C: 문제 B의 답(`b`)을 이용하여 `c`를 구하시오.  \n",
    "\n",
    "<div align='center'><a herf=\"https://blog.naver.com/sooftware/221790750668\">출처:네이버 블로그 - Sooftware 머신러닝</a></div>\n",
    "\n",
    "위와 같이 문제 A의 답이 문제 B의 계산에 필요하고, 문제 B의 답이 문제 C의 풀이에 이용되는 문제들을 생각해봅시다. \n",
    "\n",
    "> Teacher Forcing 미사용\n",
    "- 학생은 문제 A, B, C를 순서대로 풀이하고 답 a, b, c를 한꺼번에 작성하여 제출\n",
    "- 교사는 이 답안지를 보고 a, b, c를 한꺼번에 채점하여 점수를 알려줌.\n",
    "\n",
    "> Teacher Forcing 사용\n",
    "- 학생은 문제 A를 풀이하고 답 a를 제출\n",
    "- 교사는 답안지를 가져가고, 정답 a를 알려줌\n",
    "- 학생은 문제 A의 답 a를 가지고 문제 B를 풀이하고 답 b를 제출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52126a0",
   "metadata": {},
   "source": [
    "장점은 Teacher Forcing을 사용한 훈련은 더 빨리 수렴됩니다. 훈련의 초기 단계에서 모델의 예측은 매우 나쁩니다. 만약 Teacher Forcing을 사용하지 않으면 모델의 숨겨진 상태가 일련의 잘못된 예측으로 업데이트되고 오류가 누적되며 모델이 그로부터 학습하기 어렵습니다.\n",
    "\n",
    "단점으로는 추론하는 동안 일반적으로 사용할 수 있는 Ground Truth가 없기 때문에 RNN 모델은 다음 예측을 위해 자체 이전 예측을 다시 제공해야합니다. 따라서 학습과 추론 사이에 불일치가 있으며 이로 인해 모델 성능이 저하되고 불안정해질 수 있습니다. 이러한 문제를 **노출 편향(Exposure Bias)**으로 알려져 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8dac08",
   "metadata": {},
   "source": [
    "### Attention\n",
    "여기가 사실상 실제 모델이라고 생각하면 됩니다. 크게는 Encoder 파트와 Decoder 파트로 구성되어 있습니다. 이 중에서 Encoder 부분은 CNN으로 구성되어 있고, Decoder 부분은 앞서 보신 AttentionDecoder로 구성되어 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a697de92",
   "metadata": {},
   "source": [
    "```python\n",
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        FLAGS,\n",
    "        train_dataset,\n",
    "        checkpoint=None,\n",
    "    ):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.encoder = CNN(FLAGS.data.rgb)\n",
    "        \n",
    "        self.decoder = AttentionDecoder(\n",
    "            num_classes=len(train_dataset.id_to_token),\n",
    "            src_dim=FLAGS.Attention.src_dim,  # Encoder(CNN)의 output\n",
    "            embedding_dim=FLAGS.Attention.embedding_dim,\n",
    "            hidden_dim=FLAGS.Attention.hidden_dim,\n",
    "            pad_id=train_dataset.token_to_id[PAD],\n",
    "            st_id=train_dataset.token_to_id[START],\n",
    "            num_layers=FLAGS.Attention.layer_num,\n",
    "            cell_type=FLAGS.Attention.cell_type)\n",
    "\n",
    "        self.criterion = (\n",
    "            nn.CrossEntropyLoss()\n",
    "        )\n",
    "\n",
    "        if checkpoint:\n",
    "            self.load_state_dict(checkpoint)\n",
    "    \n",
    "    def forward(self, input, expected, is_train, teacher_forcing_ratio):\n",
    "        out = self.encoder(input)\n",
    "        b, c, h, w = out.size()\n",
    "        out = out.view(b, c, h * w).transpose(1, 2)  # [b, h x w, c]\n",
    "        output = self.decoder(out,\n",
    "                              expected, \n",
    "                              is_train, \n",
    "                              teacher_forcing_ratio,\n",
    "                              batch_max_length=expected.size(1))    # [b, sequence length, class size]\n",
    "        return output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc661261",
   "metadata": {},
   "source": [
    "### 모델 구조 변경 관련 TIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538de81b",
   "metadata": {},
   "source": [
    "차주 강의(10강 Bag of tricks)에서도 이진원 마스터님께서 말씀해주시겠지만, 모델 구조 변경과 관련해서 몇가지 TIP을 정리해드리자면\n",
    "- 기존 구조에서 변경\n",
    "    - CNN backbone 교체\n",
    "    - SATRN 논문대로 구현 수정\n",
    "- 단일 모델로 구조 변경\n",
    "    - CNN only model (CSTR)\n",
    "    - Transformer only model\n",
    "- Mixed\n",
    "    - Attn baseline 모델 encoder에 RNN 넣어보기\n",
    "    - SATRN baseline에서 decoder를 LSTM으로 바꿔보기 (속도향상 기대)\n",
    "    - Lanague model 활용하여 학습\n",
    "    - Ensemble (weight average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab7f3ea",
   "metadata": {},
   "source": [
    "## BREAK TIME\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "여기까지 듣는데 수고 많으셨습니다. 모델을 학습시키기 위한 기본적인 부분들은 완성했습니다.  \n",
    "이제 오피스아워 1주차 2부에서는 사실상 제일 중요한 <font color='red'>train.py</font>와 <font color='red'>inference.py</font>와 관련해서 설명드릴 예정입니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<div align='center'><font size=5><b>1부는 여기까지입니다!</b></font></div>\n",
    "<img src=\"https://opgg-com-image.akamaized.net/attach/images/20200712153418.763958.gif\" width=20%>\n",
    "<div align='center'><font size=5><b>여기까지 궁금한 점 있으셨나요?</b></font></div>\n",
    "<br>\n",
    "<div align='center'><font size=5>잠깐 쉬었다가 진행하겠습니다 :)</font></div>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf7b9b",
   "metadata": {},
   "source": [
    "## configs\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "\n",
    "학습을 위한 설정(config) 파일이 저장되어 있는 디렉토리입니다. 이를 통해서 모델 선택 및 모델별 파라미터 설정이나 학습과 관련된 하이퍼 파라미터를 손쉽게 설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30880d44",
   "metadata": {},
   "source": [
    "### YAML Ain't Markup Language\n",
    "\n",
    "> YAML 은 \"<font color='red'>Y</font>AML <font color='red'>A</font>in't <font color='red'>M</font>arkup <font color='red'>L</font>anguage\" 의 반복적인 약어(recursive acronym)로서, **인간이 읽을 수 있는** 데이터 직렬화 언어(human-readable data-serialization language) 입니다. YAML 은 데이터가 저장되거나 전송되는 구성 파일(configuration file)과 애플리케이션에서 종종 사용됩니다. YAML은 XML 과 동일한 커뮤니케이션 애플리케이션을 대상으로 하지만 최소한의 구문을 가지고 있습니다. \n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/99FED84B5EF756CE1E\" width=50%>\n",
    "\n",
    "출처: [위키피디아 Wikipedia & R, Python 분석과 프로그래밍의 친구 (by R Friend)](https://rfriend.tistory.com/540)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b1dbd",
   "metadata": {},
   "source": [
    "### Attention.yaml\n",
    "\n",
    "><font color='red'>HINT</font> : batch_size 값을 잘 수정하면서 학습을 진행하길 바랍니다.  \n",
    "batch_size 값을 너무 크게 설정하면 `OOM (Out of memory)` 가 발생할 수 있습니다.\n",
    ">```python\n",
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75de7be6",
   "metadata": {},
   "source": [
    "```\n",
    "network: \"Attention\"\n",
    "input_size:\n",
    "  height: 128\n",
    "  width: 128\n",
    "Attention:\n",
    "  src_dim: 512\n",
    "  hidden_dim: 128\n",
    "  embedding_dim: 128\n",
    "  layer_num: 1\n",
    "  cell_type: \"LSTM\" # GRU\n",
    "checkpoint: \"\"\n",
    "prefix: \"./log/attention_50\"\n",
    "\n",
    "data:\n",
    "  train:\n",
    "    - \"../../train_dataset/gt.txt\"\n",
    "  test:\n",
    "    - \"\"\n",
    "  token_paths:\n",
    "    - \"../../train_dataset/tokens.txt\"  # 241 tokens\n",
    "  dataset_proportions:  # proportion of data to take from train (not test)\n",
    "    - 1.0\n",
    "  random_split: True # if True, random split from train files\n",
    "  test_proportions: 0.2 # only if random_split is True\n",
    "  crop: True\n",
    "  rgb: 1    # 3 for color, 1 for greyscale\n",
    "  \n",
    "batch_size: 96\n",
    "num_workers: 8\n",
    "num_epochs: 50\n",
    "print_epochs: 1\n",
    "dropout_rate: 0.1\n",
    "teacher_forcing_ratio: 0.5\n",
    "max_grad_norm: 2.0\n",
    "seed: 1234\n",
    "optimizer:\n",
    "  optimizer: 'Adam' # Adam, Adadelta\n",
    "  lr: 5e-4 # 1e-4\n",
    "  weight_decay: 1e-4\n",
    "  is_cycle: True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a32857",
   "metadata": {},
   "source": [
    "## flags.py\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "config yaml 파일에서 불러온 argument들을 처리하는 코드들이 저장되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41cae8",
   "metadata": {},
   "source": [
    "```python\n",
    "\"\"\"\n",
    "Original code from clovaai/SATRN\n",
    "\"\"\"\n",
    "import os\n",
    "import yaml\n",
    "import collections\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2134e63e",
   "metadata": {},
   "source": [
    "```python\n",
    "def dict_to_namedtuple(d):\n",
    "    \"\"\"\n",
    "    Convert dictionary to named tuple.\n",
    "    \"\"\"\n",
    "    FLAGSTuple = collections.namedtuple('FLAGS', sorted(d.keys()))\n",
    "\n",
    "    for k, v in d.items():\n",
    "        \n",
    "        if k == 'prefix':\n",
    "            v = os.path.join('./', v)\n",
    "\n",
    "        if type(v) is dict:\n",
    "            d[k] = dict_to_namedtuple(v)\n",
    "\n",
    "        elif type(v) is str:\n",
    "            try:\n",
    "                d[k] = eval(v)\n",
    "            except:\n",
    "                d[k] = v\n",
    "\n",
    "    nt = FLAGSTuple(**d)\n",
    "\n",
    "    return nt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a80e826",
   "metadata": {},
   "source": [
    "```python\n",
    "class Flags:\n",
    "    \"\"\"\n",
    "    Flags object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config_file):\n",
    "        try:\n",
    "            with open(config_file, 'r') as f:\n",
    "                d = yaml.safe_load(f)\n",
    "        except:\n",
    "            d = config_file\n",
    "\n",
    "\n",
    "        self.flags = dict_to_namedtuple(d)\n",
    "\n",
    "    def get(self):\n",
    "        return self.flags\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0200a170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T10:05:11.645463Z",
     "start_time": "2021-05-28T10:05:11.608631Z"
    }
   },
   "outputs": [],
   "source": [
    "from flags import Flags\n",
    "Flags('configs/Attention.yaml').get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21b1e0",
   "metadata": {},
   "source": [
    "## utils\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "\n",
    "학습 및 추론에 사용되는 여러 함수들이 정의된 파일입니다. 특히 모델과 모델 학습과 관련된 부분이 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3280059",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch.optim as optim\n",
    "\n",
    "from networks.Attention import Attention\n",
    "from networks.SATRN import SATRN\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6824ea",
   "metadata": {},
   "source": [
    "### get_network\n",
    "해당 함수를 통해서 SATRN이나 Attention 기반의 모델을 간편하게 불러올 수 있습니다.\n",
    "\n",
    "><font color='red'>HINT</font> : CRNN 모델은 여러분들이 해볼 수 있게 남겨두었습니다 :) 완성해보세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066368ad",
   "metadata": {},
   "source": [
    "```python\n",
    "def get_network(\n",
    "    model_type,\n",
    "    FLAGS,\n",
    "    model_checkpoint,\n",
    "    device,\n",
    "    train_dataset,\n",
    "):\n",
    "    model = None\n",
    "\n",
    "    if model_type == \"SATRN\":\n",
    "        model = SATRN(FLAGS, train_dataset, model_checkpoint).to(device)\n",
    "    elif model_type == \"CRNN\": # 더미 파일 -> 현재 구현되어 있지 않음\n",
    "        model = CRNN()\n",
    "    elif model_type == \"Attention\":\n",
    "        model = Attention(FLAGS, train_dataset, model_checkpoint).to(device)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7584cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T10:08:20.067623Z",
     "start_time": "2021-05-28T10:08:18.127599Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import get_network\n",
    "from checkpoint import default_checkpoint\n",
    "get_network(\n",
    "    model_type='Attention',\n",
    "    FLAGS=Flags('configs/Attention.yaml').get(),\n",
    "    model_checkpoint=default_checkpoint['model'], # 예시니까 default에서 가져옴\n",
    "    device='cuda',\n",
    "    train_dataset=train_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c43d84",
   "metadata": {},
   "source": [
    "### get_optimizer\n",
    "학습에 필요한 옵티마이저를 불러올 수 있는 함수입니다.\n",
    "\n",
    "><font color='red'>HINT</font> : 현재는 `Adam`이나 `Adadelta`와 같은 옵티마이저만 있다면 여기에 여러분들만의 옵티마이저도 추가할 수 있게 바꿔보세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8358aa7b",
   "metadata": {},
   "source": [
    "```python\n",
    "def get_optimizer(optimizer, params, lr, weight_decay=None):\n",
    "    if optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(params, lr=lr)\n",
    "    elif optimizer == \"Adadelta\":\n",
    "        optim.Adadelta(params, lr=lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return optimizer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd8ed1",
   "metadata": {},
   "source": [
    "## metrics.py\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "\n",
    "평가에 사용되는 metric 함수들이 정의된 파일입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11149183",
   "metadata": {},
   "source": [
    "### 평가방법\n",
    "\n",
    "평가 방법은 아래와 같이 계산되어 진행됩니다.\n",
    "\n",
    "$$ \\text{Score} = 0.9 \\times \\text{Sentence Acc} + 0.1 \\times \\text{(1-WER)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274038bb",
   "metadata": {},
   "source": [
    "### sentence_acc\n",
    "문장 단위 정확도는 제출된 전체 추론 결과(수식) 중에서 몇 개의 수식이 정답(ground truth)과 <font color='red'>정확히 일치하는지</font>를 나타내는 척도입니다. 수식은 아래와 같습니다.\n",
    "\n",
    "$$ ACC(\\%) = 100 \\times \\frac{\\sum{1 * (\\text{predicted} = \\text{ground truth})}}{\\text{total number of sentences}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e4c166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T08:32:42.208206Z",
     "start_time": "2021-05-26T08:32:42.191620Z"
    },
    "code_folding": []
   },
   "source": [
    "```python\n",
    "def sentence_acc(predicted_outputs, ground_truths):\n",
    "    correct_sentences=0\n",
    "    for output,ground_truth in zip(predicted_outputs,ground_truths):\n",
    "        if np.array_equal(output,ground_truth):\n",
    "            correct_sentences+=1\n",
    "    return correct_sentences/len(predicted_outputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e3175",
   "metadata": {},
   "source": [
    "><font color='red'>HINT</font> : LaTeX 특성상 괄호나 중괄호가 중복되어 Ground truth 값과 Predicted 값이 일치하기 힘들 수 있습니다. 이걸 해결하면 성능이 많이 개선될 겁니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d18e62",
   "metadata": {},
   "source": [
    "### word_error_rate\n",
    "단어 오류율(word error rate)은 편집 거리(Edit distance)와 리벤슈테인(Levenshtein distance)라고도 불립니다. WER은 단어 단위로 <font color='red'>삽입(insertion), 삭제(deletion), 대체(substitution)된 글자 개수를 계산</font>하여 구하게 되는데, 그 수식은 아래와 같습니다.\n",
    "\n",
    "$$ WER(\\%) = \\frac{\\text{inserction} + \\text{delection} + \\text{substitution}}{\\text{total words}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf2f593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T08:32:42.222581Z",
     "start_time": "2021-05-26T08:32:42.209921Z"
    },
    "code_folding": []
   },
   "source": [
    "```python\n",
    "def word_error_rate(predicted_outputs, ground_truths):\n",
    "    sum_wer=0.0\n",
    "    for output,ground_truth in zip(predicted_outputs,ground_truths):\n",
    "        output=output.split(\" \")\n",
    "        ground_truth=ground_truth.split(\" \")\n",
    "        distance = editdistance.eval(output, ground_truth)\n",
    "        length = max(len(output),len(ground_truth))\n",
    "        sum_wer+=(distance/length)\n",
    "    return sum_wer/len(predicted_outputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77e5763",
   "metadata": {},
   "source": [
    "#### 간단한 예시\n",
    "\n",
    "|구분|1|2|3|4|5|\n",
    "|---|---|---|---|---|---|\n",
    "|Expected||스|테|이|크|\n",
    "|Ground truth|업|스|테|이|지|\n",
    "|Operation|I||||S|\n",
    "\n",
    "<br>\n",
    "\n",
    "$$ WER = \\frac{\\text{inserction} + \\text{delection} + \\text{substitution}}{\\text{total words}} =\\frac{1 + 0 + 1}{5} =\\frac{2}{5} = 0.4 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc75c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T10:12:10.816364Z",
     "start_time": "2021-05-28T10:12:10.806712Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from metrics import word_error_rate\n",
    "word_error_rate(predicted_outputs=['스 테 이 크'], \n",
    "                ground_truths=['업 스 테 이 지'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448afe24",
   "metadata": {},
   "source": [
    "## train.py\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "\n",
    "실제 학습에 사용되는 파일입니다. `config yaml 파일`을 이용하여 데이터의 경로, 모델의 하이퍼 파라미터와 같은 정보를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b3d61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T10:13:47.828125Z",
     "start_time": "2021-05-28T10:13:47.804702Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from checkpoint import (\n",
    "    default_checkpoint,\n",
    "    load_checkpoint,\n",
    "    save_checkpoint,\n",
    "    init_tensorboard,\n",
    "    write_tensorboard,\n",
    ")\n",
    "from psutil import virtual_memory\n",
    "\n",
    "from flags import Flags\n",
    "from utils import get_network, get_optimizer\n",
    "from dataset import dataset_loader, START, PAD, load_vocab\n",
    "from scheduler import CircularLRBeta\n",
    "from metrics import word_error_rate, sentence_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa20e2d0",
   "metadata": {},
   "source": [
    "### id_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5bd9fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T10:14:06.903185Z",
     "start_time": "2021-05-28T10:14:06.892462Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def id_to_string(tokens, data_loader, do_eval=0):\n",
    "    result = []\n",
    "    if do_eval:\n",
    "        special_ids = [data_loader.dataset.token_to_id[\"<PAD>\"], \n",
    "                       data_loader.dataset.token_to_id[\"<SOS>\"],\n",
    "                       data_loader.dataset.token_to_id[\"<EOS>\"]]\n",
    "\n",
    "    for example in tokens:\n",
    "        string = \"\"\n",
    "        if do_eval:\n",
    "            for token in example:\n",
    "                token = token.item()\n",
    "                if token not in special_ids:\n",
    "                    if token != -1:\n",
    "                        string += data_loader.dataset.id_to_token[token] + \" \"\n",
    "        else:\n",
    "            for token in example:\n",
    "                token = token.item()\n",
    "                if token != -1:\n",
    "                    string += data_loader.dataset.id_to_token[token] + \" \"\n",
    "\n",
    "        result.append(string)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3cdb2",
   "metadata": {},
   "source": [
    "### run_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da2ffb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T10:18:03.540789Z",
     "start_time": "2021-05-28T10:18:03.518941Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def run_epoch(\n",
    "    data_loader,\n",
    "    model,\n",
    "    epoch_text,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    lr_scheduler,\n",
    "    teacher_forcing_ratio,\n",
    "    max_grad_norm,\n",
    "    device,\n",
    "    train=True,\n",
    "):\n",
    "    # Disables autograd during validation mode\n",
    "    torch.set_grad_enabled(train)\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    losses = []\n",
    "    grad_norms = []\n",
    "    correct_symbols = 0\n",
    "    total_symbols = 0\n",
    "    wer = 0\n",
    "    num_wer = 0\n",
    "    sent_acc = 0\n",
    "    num_sent_acc = 0\n",
    "\n",
    "    with tqdm(\n",
    "        desc=\"{} ({})\".format(epoch_text, \"Train\" if train else \"Validation\"),\n",
    "        total=len(data_loader.dataset),\n",
    "        dynamic_ncols=True,\n",
    "        leave=False,\n",
    "    ) as pbar:\n",
    "        ##########################################################\n",
    "        # data loader에서 batch 단위로 데이터 불러오는 부분      #\n",
    "        ##########################################################\n",
    "        for d in data_loader:\n",
    "            input = d[\"image\"].to(device)\n",
    "\n",
    "            curr_batch_size = len(input)\n",
    "\n",
    "            ######################\n",
    "            # 예측해야하는 정답  #\n",
    "            # GT값 가져오는 부분 #\n",
    "            ######################\n",
    "            expected = d[\"truth\"][\"encoded\"].to(device)\n",
    "\n",
    "            ###############################\n",
    "            # -1은 Padding token으로 변환 #\n",
    "            ###############################\n",
    "            expected[expected == -1] = data_loader.dataset.token_to_id[PAD]\n",
    "\n",
    "            #########################\n",
    "            # model로부터 결과 출력 #\n",
    "            #########################\n",
    "            output = model(input, expected, train, teacher_forcing_ratio)  # [batch_size, seq_len, class_size]\n",
    "            decoded_values = output.transpose(1, 2)                        # [batch_size, class_size, seq_len]\n",
    "            _, sequence = torch.topk(decoded_values, 1, dim=1)             # [batch_size, 1, seq_len]\n",
    "            sequence = sequence.squeeze(1)                                 # [batch_size, seq_len]\n",
    "\n",
    "            ######################\n",
    "            # Loss 계산하는 부분 #\n",
    "            ######################\n",
    "            loss = criterion(decoded_values, expected[:, 1:])\n",
    "\n",
    "            if train:\n",
    "                optim_params = [\n",
    "                    p\n",
    "                    for param_group in optimizer.param_groups\n",
    "                    for p in param_group[\"params\"]\n",
    "                ]\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # Clip gradients, it returns the total norm of all parameters\n",
    "                grad_norm = nn.utils.clip_grad_norm_(\n",
    "                    optim_params, max_norm=max_grad_norm\n",
    "                )\n",
    "                grad_norms.append(grad_norm)\n",
    "\n",
    "                # cycle\n",
    "                lr_scheduler.step()\n",
    "                optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            ##########################\n",
    "            # 주어진 metric으로 계산 #\n",
    "            ##########################\n",
    "            expected[expected == data_loader.dataset.token_to_id[PAD]] = -1\n",
    "            expected_str = id_to_string(expected, data_loader, do_eval=1)\n",
    "            sequence_str = id_to_string(sequence, data_loader, do_eval=1)\n",
    "            wer += word_error_rate(sequence_str, expected_str)\n",
    "            num_wer += 1\n",
    "            sent_acc += sentence_acc(sequence_str, expected_str)\n",
    "            num_sent_acc += 1\n",
    "            correct_symbols += torch.sum(sequence ==expected[:, 1:], dim=(0, 1)).item()\n",
    "            total_symbols += torch.sum(expected[:, 1:]!= -1, dim=(0, 1)).item()\n",
    "\n",
    "            pbar.update(curr_batch_size)\n",
    "\n",
    "    expected = id_to_string(expected, data_loader)\n",
    "    sequence = id_to_string(sequence, data_loader)\n",
    "    print(\"-\" * 10 + \"GT ({})\".format(\"train\" if train else \"valid\"))\n",
    "    print(*expected[:3], sep=\"\\n\")\n",
    "    print(\"-\" * 10 + \"PR ({})\".format(\"train\" if train else \"valid\"))\n",
    "    print(*sequence[:3], sep=\"\\n\")\n",
    "\n",
    "    result = {\n",
    "        \"loss\": np.mean(losses),\n",
    "        \"correct_symbols\": correct_symbols,\n",
    "        \"total_symbols\": total_symbols,\n",
    "        \"wer\": wer,\n",
    "        \"num_wer\": num_wer,\n",
    "        \"sent_acc\": sent_acc,\n",
    "        \"num_sent_acc\": num_sent_acc\n",
    "    }\n",
    "    \n",
    "    if train:\n",
    "        try:\n",
    "            result[\"grad_norm\"] = np.mean([tensor.cpu() for tensor in grad_norms])\n",
    "        except:\n",
    "            result[\"grad_norm\"] = np.mean(grad_norms)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65724634",
   "metadata": {},
   "source": [
    "### main\n",
    "사실 지금까지 이 함수를 돌리기 위한 여정이었습니다. 이제 여러분들은 앞선 내용을 이해했다면 main함수가 어떻게 동작하는지 이해가 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c54a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T08:25:11.070153Z",
     "start_time": "2021-05-28T08:25:11.042191Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def main(config_file):\n",
    "    \"\"\"\n",
    "    Train math formula recognition model\n",
    "    \"\"\"\n",
    "    options = Flags(config_file).get()\n",
    "\n",
    "    #set random seed\n",
    "    torch.manual_seed(options.seed)\n",
    "    np.random.seed(options.seed)\n",
    "    random.seed(options.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "    hardware = \"cuda\" if is_cuda else \"cpu\"\n",
    "    device = torch.device(hardware)\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"Running {} on device {}\\n\".format(options.network, device))\n",
    "\n",
    "    # Print system environments\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    num_cpus = os.cpu_count()\n",
    "    mem_size = virtual_memory().available // (1024 ** 3)\n",
    "    print(\n",
    "        \"[+] System environments\\n\",\n",
    "        \"The number of gpus : {}\\n\".format(num_gpus),\n",
    "        \"The number of cpus : {}\\n\".format(num_cpus),\n",
    "        \"Memory Size : {}G\\n\".format(mem_size),\n",
    "    )\n",
    "\n",
    "    ####################################\n",
    "    # Load checkpoint and print result #\n",
    "    ####################################\n",
    "    checkpoint = (\n",
    "        load_checkpoint(options.checkpoint, cuda=is_cuda)\n",
    "        if options.checkpoint != \"\"\n",
    "        else default_checkpoint\n",
    "    )\n",
    "    model_checkpoint = checkpoint[\"model\"]\n",
    "    if model_checkpoint:\n",
    "        print(\n",
    "            \"[+] Checkpoint\\n\",\n",
    "            \"Resuming from epoch : {}\\n\".format(checkpoint[\"epoch\"]),\n",
    "            \"Train Symbol Accuracy : {:.5f}\\n\".format(checkpoint[\"train_symbol_accuracy\"][-1]),\n",
    "            \"Train Sentence Accuracy : {:.5f}\\n\".format(checkpoint[\"train_sentence_accuracy\"][-1]),\n",
    "            \"Train WER : {:.5f}\\n\".format(checkpoint[\"train_wer\"][-1]),\n",
    "            \"Train Loss : {:.5f}\\n\".format(checkpoint[\"train_losses\"][-1]),\n",
    "            \"Validation Symbol Accuracy : {:.5f}\\n\".format(\n",
    "                checkpoint[\"validation_symbol_accuracy\"][-1]\n",
    "            ),\n",
    "            \"Validation Sentence Accuracy : {:.5f}\\n\".format(\n",
    "                checkpoint[\"validation_sentence_accuracy\"][-1]\n",
    "            ),\n",
    "            \"Validation WER : {:.5f}\\n\".format(\n",
    "                checkpoint[\"validation_wer\"][-1]\n",
    "            ),\n",
    "            \"Validation Loss : {:.5f}\\n\".format(checkpoint[\"validation_losses\"][-1]),\n",
    "        )\n",
    "\n",
    "    ############\n",
    "    # Get data #\n",
    "    ############\n",
    "    transformed = transforms.Compose(\n",
    "        [\n",
    "            # Resize so all images have the same size\n",
    "            transforms.Resize((options.input_size.height, options.input_size.width)),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    train_data_loader, validation_data_loader, train_dataset, valid_dataset = dataset_loader(options, transformed)\n",
    "    print(\n",
    "        \"[+] Data\\n\",\n",
    "        \"The number of train samples : {}\\n\".format(len(train_dataset)),\n",
    "        \"The number of validation samples : {}\\n\".format(len(valid_dataset)),\n",
    "        \"The number of classes : {}\\n\".format(len(train_dataset.token_to_id)),\n",
    "    )\n",
    "\n",
    "    ###################\n",
    "    # Get loss, model #\n",
    "    ###################\n",
    "    model = get_network(\n",
    "        options.network,\n",
    "        options,\n",
    "        model_checkpoint,\n",
    "        device,\n",
    "        train_dataset,\n",
    "    )\n",
    "    criterion = model.criterion.to(device)\n",
    "    \n",
    "    model.train()\n",
    "    enc_params_to_optimise = [\n",
    "        param for param in model.encoder.parameters() if param.requires_grad\n",
    "    ]\n",
    "    dec_params_to_optimise = [\n",
    "        param for param in model.decoder.parameters() if param.requires_grad\n",
    "    ]\n",
    "    params_to_optimise = [*enc_params_to_optimise, *dec_params_to_optimise]\n",
    "    print(\n",
    "        \"[+] Network\\n\",\n",
    "        \"Type: {}\\n\".format(options.network),\n",
    "        \"Encoder parameters: {}\\n\".format(\n",
    "            sum(p.numel() for p in enc_params_to_optimise),\n",
    "        ),\n",
    "        \"Decoder parameters: {} \\n\".format(\n",
    "            sum(p.numel() for p in dec_params_to_optimise),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    #################\n",
    "    # Get optimizer #\n",
    "    #################\n",
    "    optimizer = get_optimizer(\n",
    "        options.optimizer.optimizer,\n",
    "        params_to_optimise,\n",
    "        lr=options.optimizer.lr,\n",
    "        weight_decay=options.optimizer.weight_decay,\n",
    "    )\n",
    "    optimizer_state = checkpoint.get(\"optimizer\")\n",
    "    if optimizer_state:\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"initial_lr\"] = options.optimizer.lr\n",
    "    if options.optimizer.is_cycle:\n",
    "        cycle = len(train_data_loader) * options.num_epochs\n",
    "        lr_scheduler = CircularLRBeta(\n",
    "            optimizer, options.optimizer.lr, 10, 10, cycle, [0.95, 0.85]\n",
    "        )\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=options.optimizer.lr_epochs,\n",
    "            gamma=options.optimizer.lr_factor,\n",
    "        )\n",
    "\n",
    "    #######\n",
    "    # Log #\n",
    "    #######\n",
    "    if not os.path.exists(options.prefix):\n",
    "        os.makedirs(options.prefix)\n",
    "    log_file = open(os.path.join(options.prefix, \"log.txt\"), \"w\")\n",
    "    shutil.copy(config_file, os.path.join(options.prefix, \"train_config.yaml\"))\n",
    "    if options.print_epochs is None:\n",
    "        options.print_epochs = options.num_epochs\n",
    "    writer = init_tensorboard(name=options.prefix.strip(\"-\"))\n",
    "    start_epoch = checkpoint[\"epoch\"]\n",
    "    train_symbol_accuracy = checkpoint[\"train_symbol_accuracy\"]\n",
    "    train_sentence_accuracy=checkpoint[\"train_sentence_accuracy\"]\n",
    "    train_wer=checkpoint[\"train_wer\"]\n",
    "    train_losses = checkpoint[\"train_losses\"]\n",
    "    validation_symbol_accuracy = checkpoint[\"validation_symbol_accuracy\"]\n",
    "    validation_sentence_accuracy=checkpoint[\"validation_sentence_accuracy\"]\n",
    "    validation_wer=checkpoint[\"validation_wer\"]\n",
    "    validation_losses = checkpoint[\"validation_losses\"]\n",
    "    learning_rates = checkpoint[\"lr\"]\n",
    "    grad_norms = checkpoint[\"grad_norm\"]\n",
    "\n",
    "    ###############\n",
    "    # Train model #\n",
    "    ###############\n",
    "    for epoch in range(options.num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        epoch_text = \"[{current:>{pad}}/{end}] Epoch {epoch}\".format(\n",
    "            current=epoch + 1,\n",
    "            end=options.num_epochs,\n",
    "            epoch=start_epoch + epoch + 1,\n",
    "            pad=len(str(options.num_epochs)),\n",
    "        )\n",
    "\n",
    "        #########\n",
    "        # Train #\n",
    "        #########\n",
    "        train_result = run_epoch(\n",
    "            train_data_loader,\n",
    "            model,\n",
    "            epoch_text,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            lr_scheduler,\n",
    "            options.teacher_forcing_ratio,\n",
    "            options.max_grad_norm,\n",
    "            device,\n",
    "            train=True,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        train_losses.append(train_result[\"loss\"])\n",
    "        grad_norms.append(train_result[\"grad_norm\"])\n",
    "        train_epoch_symbol_accuracy = (\n",
    "            train_result[\"correct_symbols\"] / train_result[\"total_symbols\"]\n",
    "        )\n",
    "        train_symbol_accuracy.append(train_epoch_symbol_accuracy)\n",
    "        train_epoch_sentence_accuracy = (\n",
    "                train_result[\"sent_acc\"] / train_result[\"num_sent_acc\"]\n",
    "        )\n",
    "\n",
    "        train_sentence_accuracy.append(train_epoch_sentence_accuracy)\n",
    "        train_epoch_wer = (\n",
    "                train_result[\"wer\"] / train_result[\"num_wer\"]\n",
    "        )\n",
    "        train_wer.append(train_epoch_wer)\n",
    "        epoch_lr = lr_scheduler.get_lr()  # cycle\n",
    "\n",
    "        ##############\n",
    "        # Validation #\n",
    "        ##############\n",
    "        validation_result = run_epoch(\n",
    "            validation_data_loader,\n",
    "            model,\n",
    "            epoch_text,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            lr_scheduler,\n",
    "            options.teacher_forcing_ratio,\n",
    "            options.max_grad_norm,\n",
    "            device,\n",
    "            train=False,\n",
    "        )\n",
    "        validation_losses.append(validation_result[\"loss\"])\n",
    "        validation_epoch_symbol_accuracy = (\n",
    "            validation_result[\"correct_symbols\"] / validation_result[\"total_symbols\"]\n",
    "        )\n",
    "        validation_symbol_accuracy.append(validation_epoch_symbol_accuracy)\n",
    "        validation_epoch_sentence_accuracy = (\n",
    "            validation_result[\"sent_acc\"] / validation_result[\"num_sent_acc\"]\n",
    "        )\n",
    "        validation_sentence_accuracy.append(validation_epoch_sentence_accuracy)\n",
    "        validation_epoch_wer = (\n",
    "                validation_result[\"wer\"] / validation_result[\"num_wer\"]\n",
    "        )\n",
    "        validation_wer.append(validation_epoch_wer)\n",
    "\n",
    "        ###################################\n",
    "        # Save checkpoint and make config #\n",
    "        ###################################\n",
    "        with open(config_file, 'r') as f:\n",
    "            option_dict = yaml.safe_load(f)\n",
    "\n",
    "        save_checkpoint(\n",
    "            {\n",
    "                \"epoch\": start_epoch + epoch + 1,\n",
    "                \"train_losses\": train_losses,\n",
    "                \"train_symbol_accuracy\": train_symbol_accuracy,\n",
    "                \"train_sentence_accuracy\": train_sentence_accuracy,\n",
    "                \"train_wer\":train_wer,\n",
    "                \"validation_losses\": validation_losses,\n",
    "                \"validation_symbol_accuracy\": validation_symbol_accuracy,\n",
    "                \"validation_sentence_accuracy\":validation_sentence_accuracy,\n",
    "                \"validation_wer\":validation_wer,\n",
    "                \"lr\": learning_rates,\n",
    "                \"grad_norm\": grad_norms,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"configs\": option_dict,\n",
    "                \"token_to_id\":train_data_loader.dataset.token_to_id,\n",
    "                \"id_to_token\":train_data_loader.dataset.id_to_token\n",
    "            },\n",
    "            prefix=options.prefix,\n",
    "        )\n",
    "\n",
    "        ###########\n",
    "        # Summary #\n",
    "        ###########\n",
    "        elapsed_time = time.time() - start_time\n",
    "        elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "        if epoch % options.print_epochs == 0 or epoch == options.num_epochs - 1:\n",
    "            output_string = (\n",
    "                \"{epoch_text}: \"\n",
    "                \"Train Symbol Accuracy = {train_symbol_accuracy:.5f}, \"\n",
    "                \"Train Sentence Accuracy = {train_sentence_accuracy:.5f}, \"\n",
    "                \"Train WER = {train_wer:.5f}, \"\n",
    "                \"Train Loss = {train_loss:.5f}, \"\n",
    "                \"Validation Symbol Accuracy = {validation_symbol_accuracy:.5f}, \"\n",
    "                \"Validation Sentence Accuracy = {validation_sentence_accuracy:.5f}, \"\n",
    "                \"Validation WER = {validation_wer:.5f}, \"\n",
    "                \"Validation Loss = {validation_loss:.5f}, \"\n",
    "                \"lr = {lr} \"\n",
    "                \"(time elapsed {time})\"\n",
    "            ).format(\n",
    "                epoch_text=epoch_text,\n",
    "                train_symbol_accuracy=train_epoch_symbol_accuracy,\n",
    "                train_sentence_accuracy=train_epoch_sentence_accuracy,\n",
    "                train_wer=train_epoch_wer,\n",
    "                train_loss=train_result[\"loss\"],\n",
    "                validation_symbol_accuracy=validation_epoch_symbol_accuracy,\n",
    "                validation_sentence_accuracy=validation_epoch_sentence_accuracy,\n",
    "                validation_wer=validation_epoch_wer,\n",
    "                validation_loss=validation_result[\"loss\"],\n",
    "                lr=epoch_lr,\n",
    "                time=elapsed_time,\n",
    "            )\n",
    "            print(output_string)\n",
    "            log_file.write(output_string + \"\\n\")\n",
    "            write_tensorboard(\n",
    "                writer,\n",
    "                start_epoch + epoch + 1,\n",
    "                train_result[\"grad_norm\"],\n",
    "                train_result[\"loss\"],\n",
    "                train_epoch_symbol_accuracy,\n",
    "                train_epoch_sentence_accuracy,\n",
    "                train_epoch_wer,\n",
    "                validation_result[\"loss\"],\n",
    "                validation_epoch_symbol_accuracy,\n",
    "                validation_epoch_sentence_accuracy,\n",
    "                validation_epoch_wer,\n",
    "                model,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4a3272",
   "metadata": {},
   "source": [
    "> 여러분들에게 드린 py파일에는 default값으로 지정되어있습니다.  \n",
    "현재 `Attention`모델과 `SATRN`모델과 관련된 config파일이 준비되어 있습니다.\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"-c\",\n",
    "        \"--config_file\",\n",
    "        dest=\"config_file\",\n",
    "        default=\"configs/Attention.yaml\",\n",
    "        type=str,\n",
    "        help=\"Path of configuration file\",\n",
    "    )\n",
    "    parser = parser.parse_args()\n",
    "    main(parser.config_file)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707db70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T10:23:54.440253Z",
     "start_time": "2021-05-28T10:23:54.147543Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebb1df0",
   "metadata": {},
   "source": [
    "> <font color='red'>HINT</font> : 학습시 batch_size가 너무 크면 `CUDA OOM`이 발생할 수 있습니다.  \n",
    "YAML파일을 수정해서 학습을 진행하시길 바랍니다!\n",
    ">\n",
    "```python\n",
    "---------------------------------------------------------------------------\n",
    "RuntimeError                              Traceback (most recent call last)\n",
    "<ipython-input-52-69c87ac39f45> in <module>\n",
    "----> 1 main('configs/Attention.yaml')\n",
    "\n",
    "<ipython-input-50-1f1f299bc3d4> in main(config_file)\n",
    "    181             options.max_grad_norm,\n",
    "    182             device,\n",
    "--> 183             train=True,\n",
    "    184         )\n",
    "    185 \n",
    "\n",
    "( 생략 )\n",
    "\n",
    "~/anaconda3/envs/upstage/lib/python3.7/site-packages/torch/nn/functional.py in linear(input, weight, bias)\n",
    "   1751     if has_torch_function_variadic(input, weight):\n",
    "   1752         return handle_torch_function(linear, (input, weight), input, weight, bias=bias)\n",
    "-> 1753     return torch._C._nn.linear(input, weight, bias)\n",
    "   1754 \n",
    "   1755 \n",
    "\n",
    "RuntimeError: CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 9.78 GiB total capacity; 7.61 GiB already allocated; 7.62 MiB free; 8.24 GiB reserved in total by PyTorch)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dc5c4a",
   "metadata": {},
   "source": [
    "#### 학습 시작!\n",
    "Attention 모델에서 `batch_size=32`로 설정한 경우 `1 epoch당 Train + Valid은 10분` 정도 걸립니다. GTX3080기준으로 10에폭 학습시 대략 2시간 가까이 걸립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb0879e",
   "metadata": {},
   "source": [
    "> <font color='red'>HINT</font> : YAML파일을 모두 수정하셨다면 추가적인 arguments없이 Jupyter Notebook이 아닌 `터미널`에서는 아래와 같이 실행할 수 있습니다.\n",
    ">```bash\n",
    "$ python train.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dac82e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T10:25:45.317823Z",
     "start_time": "2021-05-28T10:25:45.313651Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시간 관계상 오피스아워에서는 생략\n",
    "# main('configs/Attention.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6fda0",
   "metadata": {},
   "source": [
    "> <font color='red'>HINT</font> : 만약에 추가적으로 학습을 이어서 하고 싶다면 아래와 같이 YAML파일을 수정 후 실행하시면 됩니다.\n",
    ">```\n",
    "(생략)\n",
    "Attention:\n",
    "  src_dim: 512\n",
    "  hidden_dim: 128\n",
    "  embedding_dim: 128\n",
    "  layer_num: 1\n",
    "  cell_type: \"LSTM\"\n",
    "checkpoint: \"./log/attention_50/checkpoints/0010.pth\"  # 이 부분 수정\n",
    "prefix: \"./log/attention_50\"\n",
    "(생략)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ab1b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T10:26:27.282070Z",
     "start_time": "2021-05-28T10:26:27.278341Z"
    }
   },
   "outputs": [],
   "source": [
    "# 시간 관계상 오피스아워에서는 생략\n",
    "# %run train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c36cef",
   "metadata": {},
   "source": [
    "학습이 모두 완료되면 아래와 같이 결과가 나옵니다. \n",
    "\n",
    "```\n",
    "--------------------------------\n",
    "Running Attention on device cuda\n",
    "\n",
    "[+] System environments\n",
    " The number of gpus : 1\n",
    " The number of cpus : 20\n",
    " Memory Size : 23G\n",
    "\n",
    "[+] Data\n",
    " The number of train samples : 80000\n",
    " The number of validation samples : 20000\n",
    " The number of classes : 245\n",
    "\n",
    "[+] Network\n",
    " Type: Attention\n",
    " Encoder parameters: 5551360\n",
    " Decoder parameters: 539509 \n",
    "       \n",
    "----------GT (train)\n",
    "<SOS> \\left( a + b \\right) ^ { 2 } = a ^ { 2 } <EOS> \n",
    "<SOS> \\int _ { 0 } ^ { 1 } t e ^ { - x - 1 } d t <EOS> \n",
    "<SOS> \\tan 4 8 ^ { \\circ } = \\frac { \\overline { Q P } } { 1 } = 1 . 1 1 0 6 <EOS> \n",
    "----------PR (train)\n",
    "= x + 1 \\right) = { 2 } = 1 <EOS> { 2 } <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
    "= _ { 2 } = { 2 } } ^ ^ { 2 2 } 1 } } x <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
    "= x = = { 2 } = \\frac { 2 { 2 } } } <EOS> 2 } <EOS> \\frac <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
    "                                                                                  \n",
    "----------GT (valid)\n",
    "<SOS> \\frac { q } { p } < 0 & \\frac { r } { p } > 0 & D > 0 <EOS> \n",
    "<SOS> = \\log _ { 6 } 6 ^ { 2 } = 2 <EOS> \n",
    "<SOS> x ^ { 2 } + x - 1 <EOS> \n",
    "----------PR (valid)\n",
    "= \\frac { { { } } { { } } { { } } } { } } } { { } } <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
    "x = { { } } <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
    "x = { { } } <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
    "[1/1] Epoch 1: Train Symbol Accuracy = 0.18087, Train Sentence Accuracy = 0.00040, Train WER = 0.72567, Train Loss = 1.22221, Validation Symbol Accuracy = 0.10214, Validation Sentence Accuracy = 0.00060, Validation WER = 0.71176, Validation Loss = 1.20306, lr = 5e-05 (time elapsed 00:11:14)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f5d57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T10:26:38.046920Z",
     "start_time": "2021-05-28T10:26:38.037341Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted(os.listdir('./log/attention_50/checkpoints'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217ab90",
   "metadata": {},
   "source": [
    "## inference.py\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "\n",
    "추론에 사용되는 py 파일입니다. 모델의 체크포인트와 테스트 파일 위치, 추론에 필요한 배치 사이즈, 최대 추론 길이 등을 argument로 사용합니다. 추론을 진행한 후, \"경로\"+\\t+\"추론된 latex\"로 구성된 submission.txt를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d53e4",
   "metadata": {},
   "source": [
    "### 제출 포맷\n",
    "\n",
    "제출 포맷인 submission.txt는 <font color='red'><b>\"파일명\"+\"\\t\"+\"predicted latex\"</b></font>로 구성됩니다. 제출된 submission 파일은 서버에 \"파일명\"+\"\\t\"+\"ground truth\"로 작성된 정답 파일과 line by line(이때에 파일명이 같은지도 확인하니 파일명 순서에 주의해주시길 바랍니다.)으로 비교하며 평가가 진행됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138e4e2b",
   "metadata": {},
   "source": [
    "|파일명| Predicted LaTeX |\n",
    "|---:|---:|\n",
    "|test_00000.jpg |\t= = { { } { } } } { } |\n",
    "|test_00001.jpg |\t\\frac { { { { } } { } } } { } } \n",
    "|test_00002.jpg |\t= _ { { { { } { } } { } } } { { { } } } } } { { { { { } } } } } } } } { { { { { { } } } } } } } } \n",
    "|test_00003.jpg |\t\\left( x { 2 + 2 = 2 } = \n",
    "|test_00004.jpg |\tx = 2 \n",
    "|test_00005.jpg |\tx = { \n",
    "|test_00006.jpg |\tx = 2 \n",
    "|test_00007.jpg |\tx = x - 2 = - 2 = \n",
    "|test_00008.jpg |\t= \\left( { { } { } } { } } \n",
    "|test_00009.jpg |\t= { { { } { } } { } } { } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178beb53",
   "metadata": {},
   "source": [
    "> <font color='red'>HINT</font> : batch_size를 잘 설정하지 않으면 OOM이 발생할 수 있습니다.\n",
    ">```python\n",
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea33f5",
   "metadata": {},
   "source": [
    "이제 학습한 모델을 통해서 실제로 추론해봅시다! Attention모델의 경우 그렇게 오래 걸리지 않습니다. (대략 1분 소요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f5ad1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T10:29:08.163852Z",
     "start_time": "2021-05-28T10:27:43.303252Z"
    }
   },
   "outputs": [],
   "source": [
    "# 리더보드 제출시에는 eval_dataset\n",
    "%run inference.py --checkpoint=\"log/attention_50/checkpoints/0040.pth\" \\\n",
    "                  --batch_size=16 \\\n",
    "                  --file_path=\"../../eval_dataset/public.txt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5c0573",
   "metadata": {},
   "source": [
    "### Submission 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff20fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T10:29:08.185194Z",
     "start_time": "2021-05-28T10:29:08.166074Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./submission.txt', sep='\\t', header=None)\n",
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a7b6c",
   "metadata": {},
   "source": [
    "### 추론 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c5fe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T10:29:24.876534Z",
     "start_time": "2021-05-28T10:29:24.214611Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(20210528)\n",
    "\n",
    "samples = np.random.randint(0, 6000+1, size=8)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for count, n in enumerate(samples, start=1):\n",
    "    plt.subplot(8, 1, count)\n",
    "    test_img = plt.imread(\n",
    "        '../../eval_dataset/images/{}'.format(sub.iloc[n][0]))\n",
    "    plt.imshow(test_img, cmap='gray', interpolation='nearest')\n",
    "    plt.title('Predicted {}th image: {}'.format(n, sub.iloc[n][1]))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66abfd5",
   "metadata": {},
   "source": [
    "> <font color='red'>HINT</font> : 현재 inference시 decoding방법으로 Greedy한 Best path를 사용하고 있는데 `Beam search`로 한번 시도해보세요!\n",
    "\n",
    "<img src=\"https://d2l.ai/_images/beam-search.svg\">\n",
    "<div align='center'>출처: <a href=\"https://d2l.ai/chapter_recurrent-modern/beam-search.html\">Deep dive into deep learning</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e909f",
   "metadata": {},
   "source": [
    "## QnA\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<div align='center'><font size=5><b>궁금하신 점 있으신가요?</b></font></div>\n",
    "<br>\n",
    "<div align='center'><font size=5>슬랙 채널을 통해서 언제든지 질문주세요!</font></div>\n",
    "<br>\n",
    "<div align='center'><font size=5>여기까지 듣느라 모두 고생 많으셨습니다 :)</font></div>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76111e66",
   "metadata": {},
   "source": [
    "<div align='center'><font size=5>지금까지 6개월간 정말 고생 많으셨습니다. <br><br> 마지막 대회도 화이팅입니다!</font></div>\n",
    "\n",
    "<img src=\"https://static01.nyt.com/images/2020/01/28/multimedia/28xp-memekid3/28cp-memekid3-superJumbo.jpg\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5dd1c",
   "metadata": {},
   "source": [
    "> 오늘 발표 내용은 [여기](https://nbviewer.jupyter.org/gist/minsuk-sung/a66a991f606e1995453c8396202c6619)를 통해서 확인하실 수 있습니다.  \n",
    "> 자료는 이번 주말까지 공유해드리겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3f6bd",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "\n",
    "- deep-text-recognition-benchmark: https://github.com/clovaai/deep-text-recognition-benchmark\n",
    "- SATRN: https://github.com/clovaai/SATRN\n",
    "- Teacher forcing: https://towardsdatascience.com/what-is-teacher-forcing-3da6217fed1c\n",
    "- Beam search: https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46c151",
   "metadata": {},
   "source": [
    "## Reference\n",
    "<hr style=\"height:3px;border:none;color:#5F71F7;background-color:#5F71F7;\" />\n",
    "\n",
    "- http://boostcamp.stages.ai/competitions/43/overview/description\n",
    "- https://github.com/chaeyoung-lee/upstage-math-ocr\n",
    "- https://www.notion.so/PyTorch-collate_fn-feat-Dataset-vs-DataLoader-b1f5ceb5bac94ba78bf016fda3679a7f\n",
    "- https://lovit.github.io/nlp/2018/08/28/levenshtein_hangle/\n",
    "- https://rfriend.tistory.com/540\n",
    "- https://www.youtube.com/watch?v=55FrHTNjTCc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "목차",
   "title_sidebar": "강의 내용",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "392.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
